{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5817b1eb",
   "metadata": {},
   "source": [
    "## Grid Search for Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0be8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    KFold,\n",
    "    GridSearchCV,\n",
    "    train_test_split\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "152490b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5       6        7       8   \\\n",
       "0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  0.2419   \n",
       "1  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017  0.1812   \n",
       "2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790  0.2069   \n",
       "3  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520  0.2597   \n",
       "4  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430  0.1809   \n",
       "\n",
       "        9   ...     20     21      22      23      24      25      26      27  \\\n",
       "0  0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "       28       29  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "# scikit-learn dataset\n",
    "# https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset\n",
    "\n",
    "# dataset information: UCI Machine Learning Repository\n",
    "# https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "    \n",
    "# in short, classification problem, trying to predict whether the tumor\n",
    "# is malignant or benign\n",
    "\n",
    "# load dataset\n",
    "breast_cancer_X, breast_cancer_y = load_breast_cancer(return_X_y=True)\n",
    "X = pd.DataFrame(breast_cancer_X)\n",
    "y = pd.Series(breast_cancer_y).map({0:1, 1:0})\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21dcccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "019137fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.627417\n",
       "1    0.372583\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target percentage\n",
    "y.value_counts()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717216e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 30), (171, 30))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset into a train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b81058",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54b645b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_samples_split': 0.5, 'n_estimators': 100}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up the GBM\n",
    "gbm = GradientBoostingClassifier(random_state=0)\n",
    "\n",
    "# set up the param_grid \n",
    "param_grid = dict(n_estimators=[10, 20, 50, 100], \n",
    "                  min_samples_split=[0.1, 0.3, 0.5],\n",
    "                  max_depth=[1,2,3,4,None],\n",
    "                 )\n",
    "\n",
    "# set up kfold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "# estimate generalization error using cross_validate\n",
    "clf = GridSearchCV(gbm,\n",
    "                   param_grid=param_grid,\n",
    "                   scoring='roc_auc',\n",
    "                   refit=True, # refit the data with the best params\n",
    "                   cv=kf # k-fold\n",
    "                  )\n",
    "\n",
    "search = clf.fit(X_train, y_train)\n",
    "\n",
    "# best hyper parameters\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f7d284d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hyperparam combinations:  60\n"
     ]
    }
   ],
   "source": [
    "print('Number of hyperparam combinations: ', \n",
    "      len(param_grid['n_estimators'])\n",
    "      *len(param_grid['min_samples_split'])\n",
    "      *len(param_grid['max_depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e77afd63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.006490</td>\n",
       "      <td>0.038332</td>\n",
       "      <td>7.166313e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.977214</td>\n",
       "      <td>0.973586</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.994177</td>\n",
       "      <td>0.982468</td>\n",
       "      <td>0.975203</td>\n",
       "      <td>0.015025</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021592</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>1.563706e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.975818</td>\n",
       "      <td>0.948889</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.976414</td>\n",
       "      <td>0.015312</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.050599</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>3.843074e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.981771</td>\n",
       "      <td>0.988839</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.997671</td>\n",
       "      <td>0.993506</td>\n",
       "      <td>0.987151</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102200</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>4.963679e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.979818</td>\n",
       "      <td>0.991815</td>\n",
       "      <td>0.978413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.989100</td>\n",
       "      <td>0.008567</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>4.019425e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.977214</td>\n",
       "      <td>0.973586</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.994177</td>\n",
       "      <td>0.982468</td>\n",
       "      <td>0.975203</td>\n",
       "      <td>0.015025</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>6.325960e-07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.975818</td>\n",
       "      <td>0.948889</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.976414</td>\n",
       "      <td>0.015312</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.050408</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>5.010603e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.981771</td>\n",
       "      <td>0.988839</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.997671</td>\n",
       "      <td>0.993506</td>\n",
       "      <td>0.987151</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>2.501482e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.979818</td>\n",
       "      <td>0.991815</td>\n",
       "      <td>0.978413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.989100</td>\n",
       "      <td>0.008567</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.011787</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>4.185278e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.977214</td>\n",
       "      <td>0.973586</td>\n",
       "      <td>0.948571</td>\n",
       "      <td>0.994177</td>\n",
       "      <td>0.982468</td>\n",
       "      <td>0.975203</td>\n",
       "      <td>0.015025</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.020998</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>3.997112e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.976562</td>\n",
       "      <td>0.975818</td>\n",
       "      <td>0.948889</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.976414</td>\n",
       "      <td>0.015312</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.052009</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>4.045442e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.981771</td>\n",
       "      <td>0.988839</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.997671</td>\n",
       "      <td>0.993506</td>\n",
       "      <td>0.987151</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.101186</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>4.001802e-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.979818</td>\n",
       "      <td>0.991815</td>\n",
       "      <td>0.978413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.989100</td>\n",
       "      <td>0.008567</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.018802</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>8.275563e-06</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.979911</td>\n",
       "      <td>0.965397</td>\n",
       "      <td>0.995342</td>\n",
       "      <td>0.983117</td>\n",
       "      <td>0.983777</td>\n",
       "      <td>0.011096</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.034811</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>4.023521e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.979911</td>\n",
       "      <td>0.964762</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.990260</td>\n",
       "      <td>0.985634</td>\n",
       "      <td>0.012148</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.085404</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>8.091614e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.988932</td>\n",
       "      <td>0.983631</td>\n",
       "      <td>0.984762</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.989492</td>\n",
       "      <td>0.005545</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.171827</td>\n",
       "      <td>0.006862</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>4.042861e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.985863</td>\n",
       "      <td>0.986032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.990607</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.018403</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>1.057826e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.979911</td>\n",
       "      <td>0.965397</td>\n",
       "      <td>0.995342</td>\n",
       "      <td>0.984416</td>\n",
       "      <td>0.984036</td>\n",
       "      <td>0.011092</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.034614</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>4.081088e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.979911</td>\n",
       "      <td>0.965397</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.989610</td>\n",
       "      <td>0.985631</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.083416</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>3.918455e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.988932</td>\n",
       "      <td>0.983631</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.991558</td>\n",
       "      <td>0.988225</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.164238</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>1.835482e-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.988932</td>\n",
       "      <td>0.985119</td>\n",
       "      <td>0.986349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.990652</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>4.043811e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.991536</td>\n",
       "      <td>0.970610</td>\n",
       "      <td>0.962222</td>\n",
       "      <td>0.997671</td>\n",
       "      <td>0.974351</td>\n",
       "      <td>0.979278</td>\n",
       "      <td>0.013258</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.030003</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>4.916291e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.990234</td>\n",
       "      <td>0.971354</td>\n",
       "      <td>0.976508</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.990260</td>\n",
       "      <td>0.985361</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.074391</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>4.903121e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.985677</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.986667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992208</td>\n",
       "      <td>0.989785</td>\n",
       "      <td>0.005763</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.150217</td>\n",
       "      <td>0.003203</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>4.999198e-04</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.986979</td>\n",
       "      <td>0.988839</td>\n",
       "      <td>0.983492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995455</td>\n",
       "      <td>0.990953</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>5.082934e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.978423</td>\n",
       "      <td>0.967302</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.983483</td>\n",
       "      <td>0.009741</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.046814</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>9.217893e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.995117</td>\n",
       "      <td>0.980655</td>\n",
       "      <td>0.989524</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.991558</td>\n",
       "      <td>0.990129</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.119808</td>\n",
       "      <td>0.009129</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>8.183879e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.990234</td>\n",
       "      <td>0.985119</td>\n",
       "      <td>0.984762</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.992208</td>\n",
       "      <td>0.990309</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.254019</td>\n",
       "      <td>0.021057</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>4.842468e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.987302</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.993506</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.024806</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>3.980393e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.978423</td>\n",
       "      <td>0.967302</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.982468</td>\n",
       "      <td>0.982834</td>\n",
       "      <td>0.009678</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.047604</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>4.871698e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.994466</td>\n",
       "      <td>0.980655</td>\n",
       "      <td>0.989841</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.988312</td>\n",
       "      <td>0.989413</td>\n",
       "      <td>0.004956</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.123604</td>\n",
       "      <td>0.012552</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>4.025373e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.991558</td>\n",
       "      <td>0.987459</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.237408</td>\n",
       "      <td>0.004632</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>4.052244e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.987351</td>\n",
       "      <td>0.986984</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.992208</td>\n",
       "      <td>0.991070</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.024612</td>\n",
       "      <td>0.004068</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>1.099266e-03</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.953497</td>\n",
       "      <td>0.962222</td>\n",
       "      <td>0.997671</td>\n",
       "      <td>0.987662</td>\n",
       "      <td>0.978648</td>\n",
       "      <td>0.017486</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>8.134145e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.992187</td>\n",
       "      <td>0.977679</td>\n",
       "      <td>0.985397</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.990260</td>\n",
       "      <td>0.988794</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.094416</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>3.822470e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.986979</td>\n",
       "      <td>0.985119</td>\n",
       "      <td>0.986349</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.993506</td>\n",
       "      <td>0.990236</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.188795</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.002797</td>\n",
       "      <td>3.982680e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.984762</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999351</td>\n",
       "      <td>0.992395</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.030397</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>3.873843e-07</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.992513</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.966984</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>0.979221</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.058619</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>4.906784e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.992513</td>\n",
       "      <td>0.985119</td>\n",
       "      <td>0.976508</td>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.990260</td>\n",
       "      <td>0.988259</td>\n",
       "      <td>0.006995</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.144411</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>3.916565e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.993490</td>\n",
       "      <td>0.987351</td>\n",
       "      <td>0.964762</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.992208</td>\n",
       "      <td>0.987407</td>\n",
       "      <td>0.011937</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.288203</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>5.021400e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 0.1, 'n_...</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.991815</td>\n",
       "      <td>0.965079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991558</td>\n",
       "      <td>0.988128</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.029624</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>8.546699e-06</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.993815</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.966984</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>0.978247</td>\n",
       "      <td>0.981494</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.057215</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>4.027912e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.994466</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.986032</td>\n",
       "      <td>0.997671</td>\n",
       "      <td>0.992208</td>\n",
       "      <td>0.990950</td>\n",
       "      <td>0.005031</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.138993</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>4.879568e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.991536</td>\n",
       "      <td>0.986607</td>\n",
       "      <td>0.986032</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.991251</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.277606</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>4.974393e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 0.3, 'n_...</td>\n",
       "      <td>0.992839</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.979683</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994156</td>\n",
       "      <td>0.990954</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.024022</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>4.024105e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.990885</td>\n",
       "      <td>0.947173</td>\n",
       "      <td>0.962857</td>\n",
       "      <td>0.998447</td>\n",
       "      <td>0.978247</td>\n",
       "      <td>0.975522</td>\n",
       "      <td>0.018618</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.045401</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>2.681954e-05</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.990885</td>\n",
       "      <td>0.973958</td>\n",
       "      <td>0.982857</td>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.986364</td>\n",
       "      <td>0.986192</td>\n",
       "      <td>0.007712</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.103617</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.002575</td>\n",
       "      <td>4.858961e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.984762</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.990515</td>\n",
       "      <td>0.004813</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.213001</td>\n",
       "      <td>0.006857</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>4.111233e-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': 4, 'min_samples_split': 0.5, 'n_...</td>\n",
       "      <td>0.988932</td>\n",
       "      <td>0.993304</td>\n",
       "      <td>0.981587</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994805</td>\n",
       "      <td>0.991726</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.060996</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>4.020523e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 0.1, ...</td>\n",
       "      <td>0.992513</td>\n",
       "      <td>0.975446</td>\n",
       "      <td>0.963810</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>0.971753</td>\n",
       "      <td>0.979152</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.142799</td>\n",
       "      <td>0.012357</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>4.013100e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 0.1, ...</td>\n",
       "      <td>0.994466</td>\n",
       "      <td>0.982887</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.992236</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.984971</td>\n",
       "      <td>0.009283</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.450392</td>\n",
       "      <td>0.039324</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>3.951271e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 0.1, ...</td>\n",
       "      <td>0.991536</td>\n",
       "      <td>0.978423</td>\n",
       "      <td>0.944127</td>\n",
       "      <td>0.994565</td>\n",
       "      <td>0.990909</td>\n",
       "      <td>0.979912</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.984195</td>\n",
       "      <td>0.096772</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>1.206268e-03</td>\n",
       "      <td>None</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 0.1, ...</td>\n",
       "      <td>0.989583</td>\n",
       "      <td>0.983631</td>\n",
       "      <td>0.944127</td>\n",
       "      <td>0.995342</td>\n",
       "      <td>0.989610</td>\n",
       "      <td>0.980459</td>\n",
       "      <td>0.018540</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.053400</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>4.722074e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 0.3, ...</td>\n",
       "      <td>0.992513</td>\n",
       "      <td>0.980655</td>\n",
       "      <td>0.966984</td>\n",
       "      <td>0.993012</td>\n",
       "      <td>0.979870</td>\n",
       "      <td>0.982607</td>\n",
       "      <td>0.009610</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.116609</td>\n",
       "      <td>0.014387</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>3.938496e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 0.3, ...</td>\n",
       "      <td>0.993815</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.966032</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.987662</td>\n",
       "      <td>0.983912</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.344410</td>\n",
       "      <td>0.047205</td>\n",
       "      <td>0.002389</td>\n",
       "      <td>4.824863e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 0.3, ...</td>\n",
       "      <td>0.994792</td>\n",
       "      <td>0.983631</td>\n",
       "      <td>0.977143</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.988961</td>\n",
       "      <td>0.987663</td>\n",
       "      <td>0.006587</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.765999</td>\n",
       "      <td>0.123526</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>4.044197e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 0.3, ...</td>\n",
       "      <td>0.993490</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.989907</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.986679</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.037019</td>\n",
       "      <td>0.004427</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>4.902336e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 0.5, ...</td>\n",
       "      <td>0.992839</td>\n",
       "      <td>0.948289</td>\n",
       "      <td>0.966349</td>\n",
       "      <td>0.993789</td>\n",
       "      <td>0.975325</td>\n",
       "      <td>0.975318</td>\n",
       "      <td>0.017083</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.078211</td>\n",
       "      <td>0.013106</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>1.054727e-05</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>20</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 0.5, ...</td>\n",
       "      <td>0.990885</td>\n",
       "      <td>0.970610</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.976623</td>\n",
       "      <td>0.983193</td>\n",
       "      <td>0.009523</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.169812</td>\n",
       "      <td>0.038812</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>4.050766e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 0.5, ...</td>\n",
       "      <td>0.990885</td>\n",
       "      <td>0.981399</td>\n",
       "      <td>0.979365</td>\n",
       "      <td>0.999224</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.987317</td>\n",
       "      <td>0.007146</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.327408</td>\n",
       "      <td>0.084733</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>7.507910e-04</td>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'max_depth': None, 'min_samples_split': 0.5, ...</td>\n",
       "      <td>0.990234</td>\n",
       "      <td>0.988839</td>\n",
       "      <td>0.975556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988961</td>\n",
       "      <td>0.988718</td>\n",
       "      <td>0.007783</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.016414      0.006490         0.038332    7.166313e-02   \n",
       "1        0.021592      0.000499         0.002009    1.563706e-05   \n",
       "2        0.050599      0.000490         0.002193    3.843074e-04   \n",
       "3        0.102200      0.002301         0.002608    4.963679e-04   \n",
       "4        0.012005      0.000008         0.002195    4.019425e-04   \n",
       "5        0.021000      0.000002         0.002001    6.325960e-07   \n",
       "6        0.050408      0.000498         0.002591    5.010603e-04   \n",
       "7        0.098800      0.000399         0.002000    2.501482e-05   \n",
       "8        0.011787      0.000417         0.002204    4.185278e-04   \n",
       "9        0.020998      0.000002         0.002802    3.997112e-04   \n",
       "10       0.052009      0.001685         0.002192    4.045442e-04   \n",
       "11       0.101186      0.002132         0.002200    4.001802e-04   \n",
       "12       0.018802      0.000421         0.001998    8.275563e-06   \n",
       "13       0.034811      0.000407         0.002197    4.023521e-04   \n",
       "14       0.085404      0.003803         0.002379    8.091614e-04   \n",
       "15       0.171827      0.006862         0.002181    4.042861e-04   \n",
       "16       0.018403      0.000469         0.001989    1.057826e-05   \n",
       "17       0.034614      0.000496         0.002185    4.081088e-04   \n",
       "18       0.083416      0.001019         0.002176    3.918455e-04   \n",
       "19       0.164238      0.000977         0.001962    1.835482e-05   \n",
       "20       0.016005      0.000638         0.002194    4.043811e-04   \n",
       "21       0.030003      0.000009         0.002397    4.916291e-04   \n",
       "22       0.074391      0.002857         0.002601    4.903121e-04   \n",
       "23       0.150217      0.003203         0.002591    4.999198e-04   \n",
       "24       0.024400      0.000497         0.002592    5.082934e-04   \n",
       "25       0.046814      0.000395         0.001986    9.217893e-06   \n",
       "26       0.119808      0.009129         0.002589    8.183879e-04   \n",
       "27       0.254019      0.021057         0.002389    4.842468e-04   \n",
       "28       0.024806      0.001144         0.002184    3.980393e-04   \n",
       "29       0.047604      0.002240         0.002589    4.871698e-04   \n",
       "30       0.123604      0.012552         0.002196    4.025373e-04   \n",
       "31       0.237408      0.004632         0.002792    4.052244e-04   \n",
       "32       0.024612      0.004068         0.002996    1.099266e-03   \n",
       "33       0.040816      0.003194         0.002376    8.134145e-04   \n",
       "34       0.094416      0.003083         0.002186    3.822470e-04   \n",
       "35       0.188795      0.005432         0.002797    3.982680e-04   \n",
       "36       0.030397      0.001019         0.002003    3.873843e-07   \n",
       "37       0.058619      0.000485         0.002380    4.906784e-04   \n",
       "38       0.144411      0.001014         0.002190    3.916565e-04   \n",
       "39       0.288203      0.001159         0.002397    5.021400e-04   \n",
       "40       0.029624      0.000479         0.001984    8.546699e-06   \n",
       "41       0.057215      0.000777         0.002177    4.027912e-04   \n",
       "42       0.138993      0.002607         0.002607    4.879568e-04   \n",
       "43       0.277606      0.008201         0.002393    4.974393e-04   \n",
       "44       0.024022      0.000004         0.002177    4.024105e-04   \n",
       "45       0.045401      0.001362         0.002007    2.681954e-05   \n",
       "46       0.103617      0.002935         0.002575    4.858961e-04   \n",
       "47       0.213001      0.006857         0.002181    4.111233e-04   \n",
       "48       0.060996      0.005074         0.002195    4.020523e-04   \n",
       "49       0.142799      0.012357         0.002200    4.013100e-04   \n",
       "50       0.450392      0.039324         0.002207    3.951271e-04   \n",
       "51       0.984195      0.096772         0.003589    1.206268e-03   \n",
       "52       0.053400      0.006835         0.002400    4.722074e-04   \n",
       "53       0.116609      0.014387         0.002191    3.938496e-04   \n",
       "54       0.344410      0.047205         0.002389    4.824863e-04   \n",
       "55       0.765999      0.123526         0.002810    4.044197e-04   \n",
       "56       0.037019      0.004427         0.002381    4.902336e-04   \n",
       "57       0.078211      0.013106         0.001990    1.054727e-05   \n",
       "58       0.169812      0.038812         0.002188    4.050766e-04   \n",
       "59       0.327408      0.084733         0.002790    7.507910e-04   \n",
       "\n",
       "   param_max_depth param_min_samples_split param_n_estimators  \\\n",
       "0                1                     0.1                 10   \n",
       "1                1                     0.1                 20   \n",
       "2                1                     0.1                 50   \n",
       "3                1                     0.1                100   \n",
       "4                1                     0.3                 10   \n",
       "5                1                     0.3                 20   \n",
       "6                1                     0.3                 50   \n",
       "7                1                     0.3                100   \n",
       "8                1                     0.5                 10   \n",
       "9                1                     0.5                 20   \n",
       "10               1                     0.5                 50   \n",
       "11               1                     0.5                100   \n",
       "12               2                     0.1                 10   \n",
       "13               2                     0.1                 20   \n",
       "14               2                     0.1                 50   \n",
       "15               2                     0.1                100   \n",
       "16               2                     0.3                 10   \n",
       "17               2                     0.3                 20   \n",
       "18               2                     0.3                 50   \n",
       "19               2                     0.3                100   \n",
       "20               2                     0.5                 10   \n",
       "21               2                     0.5                 20   \n",
       "22               2                     0.5                 50   \n",
       "23               2                     0.5                100   \n",
       "24               3                     0.1                 10   \n",
       "25               3                     0.1                 20   \n",
       "26               3                     0.1                 50   \n",
       "27               3                     0.1                100   \n",
       "28               3                     0.3                 10   \n",
       "29               3                     0.3                 20   \n",
       "30               3                     0.3                 50   \n",
       "31               3                     0.3                100   \n",
       "32               3                     0.5                 10   \n",
       "33               3                     0.5                 20   \n",
       "34               3                     0.5                 50   \n",
       "35               3                     0.5                100   \n",
       "36               4                     0.1                 10   \n",
       "37               4                     0.1                 20   \n",
       "38               4                     0.1                 50   \n",
       "39               4                     0.1                100   \n",
       "40               4                     0.3                 10   \n",
       "41               4                     0.3                 20   \n",
       "42               4                     0.3                 50   \n",
       "43               4                     0.3                100   \n",
       "44               4                     0.5                 10   \n",
       "45               4                     0.5                 20   \n",
       "46               4                     0.5                 50   \n",
       "47               4                     0.5                100   \n",
       "48            None                     0.1                 10   \n",
       "49            None                     0.1                 20   \n",
       "50            None                     0.1                 50   \n",
       "51            None                     0.1                100   \n",
       "52            None                     0.3                 10   \n",
       "53            None                     0.3                 20   \n",
       "54            None                     0.3                 50   \n",
       "55            None                     0.3                100   \n",
       "56            None                     0.5                 10   \n",
       "57            None                     0.5                 20   \n",
       "58            None                     0.5                 50   \n",
       "59            None                     0.5                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'max_depth': 1, 'min_samples_split': 0.1, 'n_...           0.977214   \n",
       "1   {'max_depth': 1, 'min_samples_split': 0.1, 'n_...           0.976562   \n",
       "2   {'max_depth': 1, 'min_samples_split': 0.1, 'n_...           0.981771   \n",
       "3   {'max_depth': 1, 'min_samples_split': 0.1, 'n_...           0.979818   \n",
       "4   {'max_depth': 1, 'min_samples_split': 0.3, 'n_...           0.977214   \n",
       "5   {'max_depth': 1, 'min_samples_split': 0.3, 'n_...           0.976562   \n",
       "6   {'max_depth': 1, 'min_samples_split': 0.3, 'n_...           0.981771   \n",
       "7   {'max_depth': 1, 'min_samples_split': 0.3, 'n_...           0.979818   \n",
       "8   {'max_depth': 1, 'min_samples_split': 0.5, 'n_...           0.977214   \n",
       "9   {'max_depth': 1, 'min_samples_split': 0.5, 'n_...           0.976562   \n",
       "10  {'max_depth': 1, 'min_samples_split': 0.5, 'n_...           0.981771   \n",
       "11  {'max_depth': 1, 'min_samples_split': 0.5, 'n_...           0.979818   \n",
       "12  {'max_depth': 2, 'min_samples_split': 0.1, 'n_...           0.995117   \n",
       "13  {'max_depth': 2, 'min_samples_split': 0.1, 'n_...           0.994792   \n",
       "14  {'max_depth': 2, 'min_samples_split': 0.1, 'n_...           0.988932   \n",
       "15  {'max_depth': 2, 'min_samples_split': 0.1, 'n_...           0.988281   \n",
       "16  {'max_depth': 2, 'min_samples_split': 0.3, 'n_...           0.995117   \n",
       "17  {'max_depth': 2, 'min_samples_split': 0.3, 'n_...           0.994792   \n",
       "18  {'max_depth': 2, 'min_samples_split': 0.3, 'n_...           0.988932   \n",
       "19  {'max_depth': 2, 'min_samples_split': 0.3, 'n_...           0.988932   \n",
       "20  {'max_depth': 2, 'min_samples_split': 0.5, 'n_...           0.991536   \n",
       "21  {'max_depth': 2, 'min_samples_split': 0.5, 'n_...           0.990234   \n",
       "22  {'max_depth': 2, 'min_samples_split': 0.5, 'n_...           0.985677   \n",
       "23  {'max_depth': 2, 'min_samples_split': 0.5, 'n_...           0.986979   \n",
       "24  {'max_depth': 3, 'min_samples_split': 0.1, 'n_...           0.992188   \n",
       "25  {'max_depth': 3, 'min_samples_split': 0.1, 'n_...           0.995117   \n",
       "26  {'max_depth': 3, 'min_samples_split': 0.1, 'n_...           0.990234   \n",
       "27  {'max_depth': 3, 'min_samples_split': 0.1, 'n_...           0.992188   \n",
       "28  {'max_depth': 3, 'min_samples_split': 0.3, 'n_...           0.992188   \n",
       "29  {'max_depth': 3, 'min_samples_split': 0.3, 'n_...           0.994466   \n",
       "30  {'max_depth': 3, 'min_samples_split': 0.3, 'n_...           0.989583   \n",
       "31  {'max_depth': 3, 'min_samples_split': 0.3, 'n_...           0.989583   \n",
       "32  {'max_depth': 3, 'min_samples_split': 0.5, 'n_...           0.992188   \n",
       "33  {'max_depth': 3, 'min_samples_split': 0.5, 'n_...           0.992187   \n",
       "34  {'max_depth': 3, 'min_samples_split': 0.5, 'n_...           0.986979   \n",
       "35  {'max_depth': 3, 'min_samples_split': 0.5, 'n_...           0.988281   \n",
       "36  {'max_depth': 4, 'min_samples_split': 0.1, 'n_...           0.992513   \n",
       "37  {'max_depth': 4, 'min_samples_split': 0.1, 'n_...           0.992513   \n",
       "38  {'max_depth': 4, 'min_samples_split': 0.1, 'n_...           0.993490   \n",
       "39  {'max_depth': 4, 'min_samples_split': 0.1, 'n_...           0.992188   \n",
       "40  {'max_depth': 4, 'min_samples_split': 0.3, 'n_...           0.993815   \n",
       "41  {'max_depth': 4, 'min_samples_split': 0.3, 'n_...           0.994466   \n",
       "42  {'max_depth': 4, 'min_samples_split': 0.3, 'n_...           0.991536   \n",
       "43  {'max_depth': 4, 'min_samples_split': 0.3, 'n_...           0.992839   \n",
       "44  {'max_depth': 4, 'min_samples_split': 0.5, 'n_...           0.990885   \n",
       "45  {'max_depth': 4, 'min_samples_split': 0.5, 'n_...           0.990885   \n",
       "46  {'max_depth': 4, 'min_samples_split': 0.5, 'n_...           0.989583   \n",
       "47  {'max_depth': 4, 'min_samples_split': 0.5, 'n_...           0.988932   \n",
       "48  {'max_depth': None, 'min_samples_split': 0.1, ...           0.992513   \n",
       "49  {'max_depth': None, 'min_samples_split': 0.1, ...           0.994466   \n",
       "50  {'max_depth': None, 'min_samples_split': 0.1, ...           0.991536   \n",
       "51  {'max_depth': None, 'min_samples_split': 0.1, ...           0.989583   \n",
       "52  {'max_depth': None, 'min_samples_split': 0.3, ...           0.992513   \n",
       "53  {'max_depth': None, 'min_samples_split': 0.3, ...           0.993815   \n",
       "54  {'max_depth': None, 'min_samples_split': 0.3, ...           0.994792   \n",
       "55  {'max_depth': None, 'min_samples_split': 0.3, ...           0.993490   \n",
       "56  {'max_depth': None, 'min_samples_split': 0.5, ...           0.992839   \n",
       "57  {'max_depth': None, 'min_samples_split': 0.5, ...           0.990885   \n",
       "58  {'max_depth': None, 'min_samples_split': 0.5, ...           0.990885   \n",
       "59  {'max_depth': None, 'min_samples_split': 0.5, ...           0.990234   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.973586           0.948571           0.994177   \n",
       "1            0.975818           0.948889           0.993789   \n",
       "2            0.988839           0.973968           0.997671   \n",
       "3            0.991815           0.978413           1.000000   \n",
       "4            0.973586           0.948571           0.994177   \n",
       "5            0.975818           0.948889           0.993789   \n",
       "6            0.988839           0.973968           0.997671   \n",
       "7            0.991815           0.978413           1.000000   \n",
       "8            0.973586           0.948571           0.994177   \n",
       "9            0.975818           0.948889           0.993789   \n",
       "10           0.988839           0.973968           0.997671   \n",
       "11           0.991815           0.978413           1.000000   \n",
       "12           0.979911           0.965397           0.995342   \n",
       "13           0.979911           0.964762           0.998447   \n",
       "14           0.983631           0.984762           0.999224   \n",
       "15           0.985863           0.986032           1.000000   \n",
       "16           0.979911           0.965397           0.995342   \n",
       "17           0.979911           0.965397           0.998447   \n",
       "18           0.983631           0.977778           0.999224   \n",
       "19           0.985119           0.986349           1.000000   \n",
       "20           0.970610           0.962222           0.997671   \n",
       "21           0.971354           0.976508           0.998447   \n",
       "22           0.984375           0.986667           1.000000   \n",
       "23           0.988839           0.983492           1.000000   \n",
       "24           0.978423           0.967302           0.993789   \n",
       "25           0.980655           0.989524           0.993789   \n",
       "26           0.985119           0.984762           0.999224   \n",
       "27           0.988095           0.987302           0.999224   \n",
       "28           0.978423           0.967302           0.993789   \n",
       "29           0.980655           0.989841           0.993789   \n",
       "30           0.984375           0.973333           0.998447   \n",
       "31           0.987351           0.986984           0.999224   \n",
       "32           0.953497           0.962222           0.997671   \n",
       "33           0.977679           0.985397           0.998447   \n",
       "34           0.985119           0.986349           0.999224   \n",
       "35           0.989583           0.984762           1.000000   \n",
       "36           0.976190           0.966984           0.992236   \n",
       "37           0.985119           0.976508           0.996894   \n",
       "38           0.987351           0.964762           0.999224   \n",
       "39           0.991815           0.965079           1.000000   \n",
       "40           0.976190           0.966984           0.992236   \n",
       "41           0.984375           0.986032           0.997671   \n",
       "42           0.986607           0.986032           0.999224   \n",
       "43           0.988095           0.979683           1.000000   \n",
       "44           0.947173           0.962857           0.998447   \n",
       "45           0.973958           0.982857           0.996894   \n",
       "46           0.988095           0.984762           0.999224   \n",
       "47           0.993304           0.981587           1.000000   \n",
       "48           0.975446           0.963810           0.992236   \n",
       "49           0.982887           0.968254           0.992236   \n",
       "50           0.978423           0.944127           0.994565   \n",
       "51           0.983631           0.944127           0.995342   \n",
       "52           0.980655           0.966984           0.993012   \n",
       "53           0.982143           0.966032           0.989907   \n",
       "54           0.983631           0.977143           0.993789   \n",
       "55           0.988095           0.976190           0.989907   \n",
       "56           0.948289           0.966349           0.993789   \n",
       "57           0.970610           0.980952           0.996894   \n",
       "58           0.981399           0.979365           0.999224   \n",
       "59           0.988839           0.975556           1.000000   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.982468         0.975203        0.015025               58  \n",
       "1            0.987013         0.976414        0.015312               53  \n",
       "2            0.993506         0.987151        0.008446               30  \n",
       "3            0.995455         0.989100        0.008567               18  \n",
       "4            0.982468         0.975203        0.015025               58  \n",
       "5            0.987013         0.976414        0.015312               53  \n",
       "6            0.993506         0.987151        0.008446               30  \n",
       "7            0.995455         0.989100        0.008567               18  \n",
       "8            0.982468         0.975203        0.015025               58  \n",
       "9            0.987013         0.976414        0.015312               53  \n",
       "10           0.993506         0.987151        0.008446               30  \n",
       "11           0.995455         0.989100        0.008567               18  \n",
       "12           0.983117         0.983777        0.011096               41  \n",
       "13           0.990260         0.985634        0.012148               35  \n",
       "14           0.990909         0.989492        0.005545               16  \n",
       "15           0.992857         0.990607        0.005332               10  \n",
       "16           0.984416         0.984036        0.011092               39  \n",
       "17           0.989610         0.985631        0.011884               36  \n",
       "18           0.991558         0.988225        0.007250               24  \n",
       "19           0.992857         0.990652        0.005373                9  \n",
       "20           0.974351         0.979278        0.013258               50  \n",
       "21           0.990260         0.985361        0.009935               37  \n",
       "22           0.992208         0.989785        0.005763               15  \n",
       "23           0.995455         0.990953        0.005967                7  \n",
       "24           0.985714         0.983483        0.009741               42  \n",
       "25           0.991558         0.990129        0.005108               14  \n",
       "26           0.992208         0.990309        0.005306               12  \n",
       "27           0.993506         0.992063        0.004285                2  \n",
       "28           0.982468         0.982834        0.009678               44  \n",
       "29           0.988312         0.989413        0.004956               17  \n",
       "30           0.991558         0.987459        0.008380               27  \n",
       "31           0.992208         0.991070        0.004484                5  \n",
       "32           0.987662         0.978648        0.017486               52  \n",
       "33           0.990260         0.988794        0.006956               21  \n",
       "34           0.993506         0.990236        0.005355               13  \n",
       "35           0.999351         0.992395        0.006153                1  \n",
       "36           0.979221         0.981429        0.009804               47  \n",
       "37           0.990260         0.988259        0.006995               23  \n",
       "38           0.992208         0.987407        0.011937               28  \n",
       "39           0.991558         0.988128        0.011950               25  \n",
       "40           0.978247         0.981494        0.010163               46  \n",
       "41           0.992208         0.990950        0.005031                8  \n",
       "42           0.992857         0.991251        0.004796                4  \n",
       "43           0.994156         0.990954        0.006795                6  \n",
       "44           0.978247         0.975522        0.018618               56  \n",
       "45           0.986364         0.986192        0.007712               34  \n",
       "46           0.990909         0.990515        0.004813               11  \n",
       "47           0.994805         0.991726        0.006181                3  \n",
       "48           0.971753         0.979152        0.011433               51  \n",
       "49           0.987013         0.984971        0.009283               38  \n",
       "50           0.990909         0.979912        0.018727               49  \n",
       "51           0.989610         0.980459        0.018540               48  \n",
       "52           0.979870         0.982607        0.009610               45  \n",
       "53           0.987662         0.983912        0.009705               40  \n",
       "54           0.988961         0.987663        0.006587               26  \n",
       "55           0.985714         0.986679        0.005827               33  \n",
       "56           0.975325         0.975318        0.017083               57  \n",
       "57           0.976623         0.983193        0.009523               43  \n",
       "58           0.985714         0.987317        0.007146               29  \n",
       "59           0.988961         0.988718        0.007783               22  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf is basically a dictionary that returns the scores and other cross validation results\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67e91f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.992395</td>\n",
       "      <td>0.006153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.004285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.991726</td>\n",
       "      <td>0.006181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.991251</td>\n",
       "      <td>0.004796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.991070</td>\n",
       "      <td>0.004484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_max_depth param_min_samples_split param_n_estimators  mean_test_score  \\\n",
       "0               3                     0.5                100         0.992395   \n",
       "1               3                     0.1                100         0.992063   \n",
       "2               4                     0.5                100         0.991726   \n",
       "3               4                     0.3                 50         0.991251   \n",
       "4               3                     0.3                100         0.991070   \n",
       "\n",
       "   std_test_score  \n",
       "0        0.006153  \n",
       "1        0.004285  \n",
       "2        0.006181  \n",
       "3        0.004796  \n",
       "4        0.004484  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can order the different models based on their performance\n",
    "results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
    "\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "\n",
    "results[[\n",
    "    'param_max_depth', 'param_min_samples_split', 'param_n_estimators',\n",
    "    'mean_test_score', 'std_test_score',\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d11d05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.975522</td>\n",
       "      <td>0.018618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>None</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.975318</td>\n",
       "      <td>0.017083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.975203</td>\n",
       "      <td>0.015025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.975203</td>\n",
       "      <td>0.015025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.975203</td>\n",
       "      <td>0.015025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_min_samples_split param_n_estimators  \\\n",
       "55               4                     0.5                 10   \n",
       "56            None                     0.5                 10   \n",
       "57               1                     0.5                 10   \n",
       "58               1                     0.3                 10   \n",
       "59               1                     0.1                 10   \n",
       "\n",
       "    mean_test_score  std_test_score  \n",
       "55         0.975522        0.018618  \n",
       "56         0.975318        0.017083  \n",
       "57         0.975203        0.015025  \n",
       "58         0.975203        0.015025  \n",
       "59         0.975203        0.015025  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# worst performing models\n",
    "results[[\n",
    "    'param_max_depth', 'param_min_samples_split', 'param_n_estimators',\n",
    "    'mean_test_score', 'std_test_score',\n",
    "]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "993a6297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Hyperparameter combinations')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAApjElEQVR4nO3deZwU1bn/8c8zPfswMyyD7Lt4BRUBEcElLlcTlyhucYnxqj8TTG4W8zP+cvV6r4maxBtNNBqNisYtMW6YGOI1oiKKIiogiyyiI6Bsyj7D7Nvz+6NqsBl6hh6gp6dnvu/Xq19Unaqufk5P00+fOqdOmbsjIiLSVFqyAxARkfZJCUJERGJSghARkZiUIEREJCYlCBERiSk92QHsL0VFRT548OBkhyEiklLmz5+/2d17xtrWYRLE4MGDmTdvXrLDEBFJKWb2aXPbdIpJRERiUoIQEZGYlCBERCQmJQgREYlJCUJERGJKWIIws4fNbKOZLWlmu5nZ3WZWbGaLzWxs1LbLzOzj8HFZomIUEZHmJbIF8ShwagvbTwOGh4/JwH0AZtYd+BlwFDAe+JmZdUtgnCIiEkPCEoS7zwK2trDLJOBxD7wDdDWzPsDXgFfcfau7bwNeoeVEIyIiCZDMPoh+wJqo9bVhWXPlIvvswgfmcOEDc5IdhkhKSOlOajObbGbzzGzepk2bkh2OiEiHkswEsQ4YELXePyxrrnw37j7F3ce5+7iePWNOJSIiInspmQliGvBv4WimCUCJu28ApgNfNbNuYef0V8MyERFpQwmbrM/MngROAIrMbC3ByKQMAHe/H3gROB0oBiqAK8JtW83sFmBueKib3b2lzm6RNtPYf/H0VROTHIlI4iUsQbj7xXvY7sD3m9n2MPBwIuISkY5JyXv/S+lOahERSRwlCDT0UaSj0v/tfaMEISIiMSlBiIhITEoQraDmqoh0JkoQbaSzJpfm6h2rvLO+R/tC75kkkhKESAejpCH7ixKEiIjEpAQhIiIxKUEkmU4HiEh7pQQhIiIxKUE0Q7/s2y/9bUTahhKEiEgzOvuPESWIfZSID1C81wh09g+viCSWEoS0a8lMgkrA0tkpQSRAe/tiac3VzK15fnvX3pLLvv4dRNqaEkQHs69fNqn6ZZWqcbcVvT+yN5QgZK/oC6fj0t9WGilBiMheUSLp+JQgREQkJiUI2W866y/Kzlpv6fiUIETovF/ynbXeyZJq77cShIiIxKQEIZIiUu3Xp6Q+JQgR2SMlp85JCUJERGJSghCR/UYtjY5FCUJERGJSggA27aimurY+2WGIdEhqVaSu9GQHkGxrtlawcnM5AF+7cxYnjTiAkw4+AHfHzJIcnXRWjV+oT181McmRJEYy69ce39v2GBMoQTCgey6j+heyvaKG7nmZPDhrJfe9/gnpaUZhTgbTFq3n+IN6UpiTkexQRTq89vpF2Vl1+gQBkJMRIacwhycnT6C0qpY3P9rMz6YtYXtFLT96cgGRNOPIwd3YUFJJ99zMZIcrItIm1AfRREF2BmeM6sOwnl0YO7Arz31vIld9ZSjbymv5bGslC9eW8O3H5vHmx5toaPBkhysibawz3RJYLYgWmBlHDOrOEYO689NTD2bSPW+xaUc1Cz7bxqvLv2Bozzzq652iLmpViCSKTjsljxJEK2RnRBjQPZfHrxzPPz/4nMfmrGbBZ9v5dGsFE2+dwYEHdGFYzy58UVpFdkaElZvK6F2YTW6m3mYRST365toLWekRzh7Tj7PH9OPrd7/J9spajhzcneKNZTwzbw0VNcGQ2ZN++wYA+Vnp1DY0kBFJ45KH3tl5HMNYvqEUgEv/+O7O8g8/30FORoSZKzYyfnB38rL0ZxKJplZF29A3zz7Ky0onLyudOy8cDUBDg3PufbOpqm1g8leG8kVpNV+UVjFt4Tpq653q2gYAGnsvGrsxyqrr8HC5tr6B0qparnhkLhkRY8yAbqzbXklOZoSZH24kOyNCbmaEipo6ImlGVW092RmRtq24iHR4CU0QZnYqcBcQAR5y9/9psn0Q8DDQE9gKfMvd14bbfg2cEe56i7s/nchY95e0NCMrPUJWeoRzx/bfWd7YUmj6iyfWL6ELH5hDQ4Nz9ckH8VbxZmYXb2bd9koArnh07m6vefB/v0ReZoTuXTLZWl5DZiSNO15ewYg+BRzcp0DXdIjIXklYgjCzCHAvcAqwFphrZtPcfVnUbr8BHnf3x8zsJOBW4FIzOwMYC4wGsoDXzeyf7l6aqHjbm7Q049jhRRw7vAiA8/4wm5r6Bm6edCiVtfVU1tRz64vLqW9wzh83gC1lNWyrqOG1DzdSWVvPPTOLd7ZO0iwYynv5I+9RmJNBQXYGhTkZbCipJCOSxuzizfTMz6JnlywlE+m0dNpqd4lsQYwHit19JYCZPQVMAqITxEjgmnB5JvB8VPksd68D6sxsMXAq8EwC423X0iNppEfSGDOw286yKbNWAvD9Ew/cWdb4IX/s/4zn4y/KWL6hlDteWUFlbT1by2tYtbmc0spaSqvqqA8zyCUPfdn/YUCX7HQenLWSk0f2YkhRXhvUTkSaau7sQjxl+0siE0Q/YE3U+lrgqCb7LALOJTgNdQ6Qb2Y9wvKfmdlvgVzgRHZNLACY2WRgMsDAgQP3d/wpLTsjwmH9CzmsfyHPvb8W2PUD5O6cf//b1NY7N5w+go07qtm0o5ops1ZSWlXLL19czi9fXM6wnnlU1NTTNSeD6rp6stLV1yHSWSS7k/pa4B4zuxyYBawD6t39ZTM7Engb2ATMAXabTc/dpwBTAMaNG6er1lrBzEhPSyM9DY4a2mNn+fSlnwPwm28czozlX/Dq8o3MLt7MhpIqDr/pZY4c3J2jhxVRVl1HXqaShUhHlsgEsQ4YELXePyzbyd3XE7QgMLMuwHnuvj3c9kvgl+G2vwAfJTBWaWJA91wuP2YIlx8zhPPum82OyjqOPrCItz/ZzK9f+nDnfof9fDpdczPompPJp1vKyUqPMG3Reo47sIhuebqAUCSVJTJBzAWGm9kQgsRwEfDN6B3MrAjY6u4NwPUEI5oaO7i7uvsWMxsFjAJeTmCs0oL0tDS65WXy87MOAYLp0S+aMoeq2npOGdmbkspatlfUsGpzGVsravjRkwswg1H9Ctm0o5r87AzeXblll2OWVtYC7FK+o6qWHA3XFWk3EpYg3L3OzH4ATCcY5vqwuy81s5uBee4+DTgBuNXMnOAU0/fDp2cAb4ajaUoJhr/WJSpWaZ2e+VkUdckC2Jk0IOgsc3euP30Esz7azKyPN7G+pApKqrhwyjsxjxWr/Jw/zOa4A4s47qCeNLiTplFVIkmR0D4Id38ReLFJ2Y1Ry1OBqTGeV0UwkklSjJkxZmA3xgzsxtUnD+e8P8ymoqae//76rn/Om18IxhzcGFV+0z+WUlYd/A64Z2Yxd79WTJoFHe6XPPQOhTnB8NzPtlaQlxlRp7lIgiW7k1o6uPRIGgU5aRx9YNEu5Y3314gu75qbSdfcTJ6+aiIlFbXMWbmZG/++lJq6BqpqG/i8ZAcllXVsKavGgYm3vsY3xvXnm+M1gk0kEZQgpF0qzM3g1EP78Mjs1cCuQ3QvuP9tSqvqGNwjj4feXMUDb6ykMCedbrmZ/H3hOjIjaWRlpFFSWUuawadbyunRJUujrkRaSQlCUo5ZcLe/+y89gs9Lqnh67hrumfkxJZUVXP3Uwt32P/721wHISk/DHTLT03j4rVWcd0R/3SlQpAVKEJLSehdmc/XJw5ldvImaugbuuHA01XUNVNc1cP1zi2lwZ/JXhrGlvJotZTU89/5aKmvqufmFZdw+fQWTRvflWxMGJbsaIu2SEoR0CGZGVkaEoT277CwrCFsH5x3x5aSJC9dsB+C/vz6SJ979lOcXrOepuWvIy4pQmJ3BPxatZ0SffAb30BQjIkoQzdCEXR3bof0KufXcUVx32gj++v5abp++gg0lVfzwyQVAcDoqPc3IiKTxwycXkJcZITcznTXbKkhPM6bOX0v3vAy65WZSVVtPRkR375WORwlCOrXCnAyuOGYILy35nAZ3bjrrUJZvKOXDz0t5Zt4aauobWLquhPKaOiqq69kRDsO99tlFux1r4q0zGFKUx+CiPDaUVJKZHuGlJRt2bt9aXgOwSxnAtvIa8tUXIu2QEoRIKM2MkX0LGNm3AIDFa0uA3UdQ1TvcecFotlbUsLW8ml+8sJyaugbGD+3Oqs3l/O/iDZSEV4p/98/v7/Y6scrSDP7r+Q/4t4mDOahXfiKqJ9JqShAirWBmpBsM7JHLwB65ADzwRjDt+h0XjN6537l/mE1tfQO3nX/4zrKfTg1aHdFlANc8vZBNZdU8M28tf37nMyYM7c6W8hq656pVIcmlBCGSABmRNDIiaYzoU7CzLDcz+O8WXQZBZ3pBTgb3fesInpm3hj/N+ZR12yvJjKTxh9eLufjIgZr4UJJijwnCzHoBvwL6uvtpZjYSmOjuf0x4dClKHdyyN7rnZfLd44fxneOGctrvZvF5aRW3vbSCu179mHPG9KOipm5nkhFpC/F82h4FHgFuCNc/Ap4GlCBQMpD9L5JmdMvLpFteJjdPOpRH317FX99fR3VdA4U56cxbvZVxg7snO0zpBOIZm1fk7s8ADRDM0kqMm/eksqevmqgvemmX/qV3PreeO4p3rv9X+nfLoby6nvPvn8MlD73De6u2Jjs86eDiaUGUh7cBdQAzmwCUJDSqTk7JSprqlpdJv6459C7I5muH9OaBWZ9wwQNzyM9Op6hLJs/OW4OZYQT360hPM7aUVdMjnJZdZG/EkyCuAaYBw8xsNtATOD+hUcleU3Lp2CJpxne+MpRvTRjEX977jP/553JWba7g/01dvNu+R/ziVYb1zGP8kB5sLqsmP1v9F9I6LX5iwju7HR8+/gUwYIW717ZBbO2OvnylvcjJjHDlsUN4ackGausa+P03xwLgDj988n1q6xs48/B+zF29lRcWr2dHVXCB39n3zuasw/tyxqg+9CrITmYVJAW0mCDcvd7MLnb3O4GlbRSTxBArOSlhSVo4B9WA7rk7y7IzImRnRPjeCcP4HsOob3Am3fMWJZW11NY3cPMLy7jlf5cxYUgPNpZWUZSv01ASWzxtztlmdg/ByKXyxkJ33/1yUGm1tviSb81rKOl0PJE0Iy8rnbysdJ6+aiLFG8t4YfF6pi1az6otFWwur2FbeY2utZDdxJMgRof/3hxV5sBJ+z0aaVNKBp3TgQd04ccnH8TV/zqck+94g5Wby5l072weumycpvmQXewxQbj7iW0RiIi0LTOjqEsW2ekRNpZVc+4f3ubui0cnOyxpR/Z4HYSZFZrZHWY2L3z81swK2yI4SS26niQ1dclO5+/fP4ZBPXK58rF5bCipxN2THZa0A/GcYnoYWAJcEK5fSnBl9bmJCqoj0hentGd9u+bw7Hcn8pNnFvHPJZ+zZmslx932Gn0KcuhdmM1nWyvITE/j1WVf0K9bDv265SQ7ZGkD8SSIYe5+XtT6TWa2MEHxSDukEVSdQ25mOvd+cyyn3PkGFTX1jB3YjQ0lVSxYs43PS6pw4NuPz9u5f8SMnMwIv315BUcPK2LsoK5Ji10SI54EUWlmx7r7WwBmdgxQmdiwRCQZ0tKCfgmAuy4as7P8gvvfprbeufHMkazfXsW67RX88a1VlFXXce/MYn7/WjHZGWlkRtIozMlg4ZrtHNq3gHTdaS+lxZMgvgc8FtXvsA24PGERiUi7Y2ZkphtjBnZjzMCgbMbyjQA8eNk43l25lbc/2cxT761hzbZKzr53NvlZ6Rw1tDsbSqoozEnH3TGzJNZCWiueUUwLgcPNrCBcL010UCKSOgqyMzhlZC9OGdmLZetLqa1v4IpjhvD2J1uY88lmPttaAcDxt7/OqYf25muH9FKySBHx3A/iV8Bt7r49XO8G/MTd/yvBsYlICsqIpHHm4X058/C+AJx971uUVNQyqCiPR2avYsqslWREjG65mTw3fy2j+hcytGcXImlKGO1NPKeYTnP3/2xccfdtZnY6oAQhInuUlR7hgIIIj14xntKqWmZ+uJGbpi1lc1k1P3k2uA1rbmaEkX0KWLutgt6FGiHVXsSTICJmluXu1QBmlgNo8hYRabWC7Awmje7HX979DHfnl+ccxuK1JXywroQl60r4Ykc12ypqWbutgv7dcvd8QEmoeBLEE8AMM3skXL8CeCxxIYlIZ2BmDO+Vz/Be+Zx3RH8Azrj7TT78fAcXPvAOT02esMskhNL29jgGzd1/DfwCGBE+bnH32xIdmIh0Pl2y0hnRO5+y6joumvIOn22pSHZInVo8U23kAS+7+7XAg0CWmWUkPDIR6ZTystJ54ttHUV5Tx4VT5lBV26HucJxS4jnFNAs4Lhy99BIwD7gQuCSRgYmArtjurA7tV8hfvj2BSx56h2UbSunfNYcXP9hAfnY6+dkZVNbUk5Whi/ASLZ4EYe5eYWZXAve5+22aakNEEm1k3wKenDyBM3//Fqu2VPDvT+x6C5rsjDTWbK1QP0UCxZUgzGwiQYvhyrAskriQRFpPLY2O6eDeBYwe0JXaugZuPW8UO6rq2FFVyy9eWMZn4RXbD142jrEDuyU71A4pngRxNXA98Dd3X2pmQ4GZiQ1LpG0pwbRfjbdVHdGnYGfZlFkryc/OYHtlLRdPeYc7LxydvAA7sHim2phF0A/RuL4S+FEigxJpSbxf5qn8pZ/KsbeVnMwIj1xxJJP/NJ9/f+J9BnTLoU9hdrLD6lAS2stjZqea2QozKzaz62JsH2RmM8xssZm9bmb9o7bdZmZLzWy5md1tmrhFRJro0SWLJ759FGeM6sOabZV8sqmctds0NHZ/iecU014xswhwL3AKsBaYa2bT3H1Z1G6/AR5398fM7CTgVuBSMzsaOAYYFe73FnA88Hqi4pXEaO6XsO4xIftLdkaE3180hoWfbWP99ipOuP11zhvbn++dMCzZoaW8eCbrO8bdZ++pLIbxQHF4SgozewqYBEQniJHANeHyTOD5cNmBbCATMCAD+GJPsYokgxJb8qWlGf275dIzP4vRA7rx5Huf8ez8NXTLzaRvV83ttLfiOcX0+zjLmuoHrIlaXxuWRVvEl7cuPQfIN7Me7j6HIGFsCB/T3X150xcws8mN98retGlTHCGJSEeWlR7h52cdwpv/cSLfOW4o2ypq+GBdCdf/dTEbd1QlO7yU02wLIhzaejTQ08yuidpUwP4b5notcI+ZXU7QEb4OqDezAwmm9Wjsk3jFzI5z9zejn+zuU4ApAOPGjdNd1kUEgAPys7n+9BHMXb2V9dsrmTp/LdMWruffTzyQhgYnTVOLx6WlFkQm0IUgieRHPUqB8+M49jpgQNR6/7BsJ3df7+7nuvsY4IawbDtBa+Iddy9z9zLgn4Da8SLSKhmRNAb1yOPl/3s8xw4v4vbpK1i0toRNO6op3riD8uq6ZIfYrjXbgnD3N4A3zOxRd/8UwMzSgC5x3lVuLjDczIYQJIaLgG9G72BmRcBWd28guNbi4XDTZ8B3zOxWgj6I44HftaZiIiKNhhTl8cCl45jzyRaufGwuKzeXc/Idwej9/Ox0+hbm8EVpFd3zMqmpayAzXdN4QHyjmG41s+8C9QRf+gVmdpe7397Sk9y9zsx+AEwnOCX1cHih3c3APHefBpwQHt8JTjF9P3z6VOAk4AOCDuuX3P0fra+eyN5T53PHM3FYDw7tW0BZdR1XHT+MDSVVbNheyfqSKlZvKWfl5nKO/fVrXHb0YC45amCyw026eBLESHcvNbNLCE71XAfMB1pMEADu/iLwYpOyG6OWpxIkg6bPqweuiiM2EZFWMTPywxsXRbvg/rcpqazlgIJsbp++gnteK6YgO51+3TrvKKh4EkRGOL332cA97l4b/uIXkWa05joPtVTaBzOja24mf7ryKD78vJQ/vrmKqfPXUlPfkOzQkiaeBPEAsJpgSOosMxtE0FEtIm1IiaTtHNy7gNu/cThvf7KZddurWLq+hEP6FiY7rDYXzx3l7nb3fu5+ugc+BU5sg9hERJKqd0E2kTTjrlc/TnYoSRHPHeV6mdkfzeyf4fpI4LKERyYikmTpkTR6F2Tx8rIvWLKuJNnhtLl4xnI9SjASqW+4/hHw4wTFIyLSrvQuyCY/O53fdcJWRDwJosjdnwEaIBi+SjDkVUSkw0uPpPHtY4fy6vIv+GBt52pFxJMgys2sB8H1CJjZBKBzvUsi0qldcexgCrLT+d2rHyU7lDYVT4K4BpgGDDOz2cDj6IZBItKJFGRnMPkrQ5nx4UbKOtH0HPEkiKUEU10cTXDx2iHAh4kMSkSkvbns6MF0zc1g3bbKZIfSZuK5DmKOu48lSBQAmNn7wNiERSUi0s7kZ2fwneOGcvv0FWwtr6F4446d2yprgm7ZpmXpkdSeNbal6b57E9y/IcfMxhBMmgfBdN+5bRCbiEi7ctnRg7nzlY/4eGPZzsn+ojUtM4Op89dy/hH9d9s3FbTUgvgacDnBNN2/5csEUQr8Z2LDEhFpf7pkpTOiTwGVNXVcffJBO8vvCjuvm5Zt3FHNtc8uYvHa7fzXGSPbPN591dJ0348Bj5nZee7+XBvGJJIwmq5C9lVuZoTczAhnHt53Z9mf3/kUYLey7nmZHD6gKw++uYpl60upb/CUmkp8j30QSg4iInvHzLjhjJEc1r8r/zF1MXUNDQw/oEuyw4pbPJ3UItJBqUXVNs46vC8H9erCpHtms2zDDib8agYH98nn4N4FjOiTT0VNHZnp++tOzvuPEoRIK6TqF2qqxt2RHNy7gEP7FrCprJojBnVn+YZSZhdvprb+y7snHHLjS/QqyOaAgiyKN5aRZvD/nl20c/vKTWXA7mVZCUoucSUIMzsaGBy9v7s/npCIREQ6qPRIGn0Kc7jzwtEA1NQ18MmmMn7wl/epqWvglJG9+WJHFRtLqyirrsMdZhdv3vn8ksrgIr2mZblZiblFzx4ThJn9CRgGLOTLOZic4IpqERHZS5npaYzoU0BRlywAbjzzy5FOFz4wB9i19ddSWSLE04IYR3DbUd1FTkSkE4lnvNUSoHeiAxERkfYlnhZEEbDMzN4DqhsL3f2shEUlIiJJF0+C+HmigxCR9k2joDqneC6Ue6MtAhERkfYlnlFME4DfAyOATCAClLt7QYJjE5G9kMxf+7FeW62P1BXPKaZ7gIuAZwlGNP0bcFCLzxCRNqEvX0mkuGaNcvdiIOLu9e7+CHBqYsMSEZFki6cFUWFmmcBCM7sN2ECciUVEUk9btEqaew21iNqXeL7oLw33+wFQDgwAzktkUCIiknzxjGL61MxygD7uflMbxCQiKUC/9ju+PbYgzOxMgnmYXgrXR5vZtATHJSIiSRbPKaafA+OB7QDuvhAYkrCIRESkXYgnQdS6e0mTMk3cJyLSwcUzimmpmX0TiJjZcOBHwNuJDUtERJItngTxQ+AGgon6ngSmA7ckMigRkZaog7xtxDOKqYIgQdyQ+HBERHalZJA8zSaIPY1U0nTfIiIdW0stiInAGoLTSu8C1iYRiYhIu9DSKKbewH8ChwJ3AacAm939jXinADezU81shZkVm9l1MbYPMrMZZrbYzF43s/5h+YlmtjDqUWVmZ7e6diIisteaTRDhxHwvuftlwASgGHjdzH4Qz4HNLALcC5wGjAQuNrORTXb7DfC4u48CbgZuDV97pruPdvfRwElABfByq2omIiL7pMVOajPLAs4ALgYGA3cDf4vz2OOBYndfGR7rKWASsCxqn5HANeHyTOD5GMc5H/hn2FkuIiJtpNkWhJk9DswBxgI3ufuR7n6Lu6+L89j9CPowGq0Ny6ItAs4Nl88B8s2sR5N9LiLoB4kV42Qzm2dm8zZt2hRnWCIiEo+W+iC+BQwHrgbeNrPS8LHDzEr30+tfCxxvZguA44F1QH3jRjPrAxxGcO3Fbtx9iruPc/dxPXv23E8hiYgItHCKyd339Z4P6wimBm/UPyyLfo31hC0IM+sCnOfu26N2uQD4m7vX7mMsIiLSSom88c9cYLiZDQlvOHQRsMu1FWZWZGaNMVwPPNzkGBfTzOklERFJrIQlCHevI7jJ0HRgOfCMuy81s5vNrPEiuxOAFWb2EdAL+GXj881sMEELJK4htSIisn/FMxfTXnP3F4EXm5TdGLU8FZjazHNXs3untoiItBHdW1pERGJSghARkZiUIEREJCYlCBERiSmhndQiIqlC953YnVoQIiISkxKEiIjEpAQhIiIxKUGIiEhMShAiIhKTEoSIiMSkBCEiIjHpOggR6VR0vUP81IIQEZGYlCBERCQmJQgREYlJCUJERGJSghARkZiUIEREJCYlCBERiUkJQkREYlKCEBGRmJQgREQkJiUIERGJSQlCRERiUoIQEZGYlCBERCQmJQgREYlJCUJERGJSghARkZiUIEREJCbdclREOgTdSnT/UwtCRERiUoIQEZGYdIpJRDqsfT3t1NlPWylBiIi0QqykEW9ZqtEpJhERiSmhCcLMTjWzFWZWbGbXxdg+yMxmmNliM3vdzPpHbRtoZi+b2XIzW2ZmgxMZq4iI7CphCcLMIsC9wGnASOBiMxvZZLffAI+7+yjgZuDWqG2PA7e7+whgPLAxUbGKiMjuEtkHMR4odveVAGb2FDAJWBa1z0jgmnB5JvB8uO9IIN3dXwFw97IExiki0u60h76ORJ5i6gesiVpfG5ZFWwScGy6fA+SbWQ/gIGC7mf3VzBaY2e1hi2QXZjbZzOaZ2bxNmzYloAoiIp1XsjuprwWON7MFwPHAOqCeoGVzXLj9SGAocHnTJ7v7FHcf5+7jevbs2WZBi4h0BolMEOuAAVHr/cOyndx9vbuf6+5jgBvCsu0ErY2F7r7S3esITj2NTWCsIiLSRCITxFxguJkNMbNM4CJgWvQOZlZkZo0xXA88HPXcrmbW2Cw4iV37LkREJMESliDCX/4/AKYDy4Fn3H2pmd1sZmeFu50ArDCzj4BewC/D59YTnF6aYWYfAAY8mKhYRURkdwm9ktrdXwRebFJ2Y9TyVGBqM899BRiVyPhERKR5ye6kFhGRdkoJQkREYtJkfSIiSdZeJ/ZTC0JERGJSghARkZiUIEREJCYlCBERiUkJQkREYtIoJhGRNtJeRys1Ry0IERGJSQlCRERiUoIQEZGYlCBERCQmJQgREYlJCUJERGJSghARkZiUIEREJCYlCBERicncPdkx7Bdmtgn4dB8OUQRs3k/hJFtHqgt0rPp0pLqA6tOexVuXQe7eM9aGDpMg9pWZzXP3ccmOY3/oSHWBjlWfjlQXUH3as/1RF51iEhGRmJQgREQkJiWIL01JdgD7UUeqC3Ss+nSkuoDq057tc13UByEiIjGpBSEiIjEpQYiISEydPkGY2almtsLMis3sumTH01pm9rCZbTSzJVFl3c3sFTP7OPy3WzJjjJeZDTCzmWa2zMyWmtnVYXmq1ifbzN4zs0VhfW4Ky4eY2bvhZ+5pM8tMdqzxMrOImS0wsxfC9VSuy2oz+8DMFprZvLAsJT9rAGbW1cymmtmHZrbczCbua306dYIwswhwL3AaMBK42MxGJjeqVnsUOLVJ2XXADHcfDswI11NBHfATdx8JTAC+H/49UrU+1cBJ7n44MBo41cwmAL8G7nT3A4FtwJXJC7HVrgaWR62ncl0ATnT30VHXC6TqZw3gLuAldz8YOJzg77Rv9XH3TvsAJgLTo9avB65Pdlx7UY/BwJKo9RVAn3C5D7Ai2THuZb3+DpzSEeoD5ALvA0cRXN2aHpbv8hlszw+gf/glcxLwAmCpWpcw3tVAUZOylPysAYXAKsKBR/urPp26BQH0A9ZEra8Ny1JdL3ffEC5/DvRKZjB7w8wGA2OAd0nh+oSnZBYCG4FXgE+A7e5eF+6SSp+53wE/BRrC9R6kbl0AHHjZzOab2eSwLFU/a0OATcAj4SnAh8wsj32sT2dPEB2eBz8dUmoss5l1AZ4DfuzupdHbUq0+7l7v7qMJfn2PBw5ObkR7x8y+Dmx09/nJjmU/OtbdxxKcYv6+mX0lemOKfdbSgbHAfe4+BiinyemkvalPZ08Q64ABUev9w7JU94WZ9QEI/92Y5HjiZmYZBMnhCXf/a1icsvVp5O7bgZkEp2G6mll6uClVPnPHAGeZ2WrgKYLTTHeRmnUBwN3Xhf9uBP5GkMBT9bO2Fljr7u+G61MJEsY+1aezJ4i5wPBwJEYmcBEwLckx7Q/TgMvC5csIzuW3e2ZmwB+B5e5+R9SmVK1PTzPrGi7nEPSnLCdIFOeHu6VEfdz9enfv7+6DCf6fvObul5CCdQEwszwzy29cBr4KLCFFP2vu/jmwxsz+JSz6V2AZ+1qfZHeuJPsBnA58RHBu+IZkx7MX8T8JbABqCX5FXElwbngG8DHwKtA92XHGWZdjCZrAi4GF4eP0FK7PKGBBWJ8lwI1h+VDgPaAYeBbISnasrazXCcALqVyXMO5F4WNp4//9VP2shbGPBuaFn7fngW77Wh9NtSEiIjF19lNMIiLSDCUIERGJSQlCRERiUoIQEZGYlCBERCQmJQjZa2ZW1mT9cjO7J1nxJJuZ/djMcpMdR1Nm9nMzuzZGeV8zm7oPx92lvmb2YuN1H9IxKEFIyoi6YndfjhHZH7E048cEk/LFLcHxtMjd17v7+Xves1k/Jqq+7n66B1eMSwehBCH7nZnlm9mqcNoMzKygcd3MXjezu8I5+JeY2fhwn7zw3hbvhZONTQrLLzezaWb2GjDDzE4ws1lm9r8W3MfjfjNLC/e9z8zmRd97ISxfbWa/NrP3gW+Y2XfMbG54n4bnGn8Fm9mj4THeMbOV4Ws9HM6t/2jU8b5qZnPM7H0ze9bMupjZj4C+wEwzm9ncfrHiafLe9TKzv4WxLTKzo8Pya8L3a4mZ/TgsG2zB3P+PmtlHZvaEmZ1sZrMtmP9/fNShDw9j+djMvhP1/CVR7/NfzeylcJ/bomLa7X1tpr6rzaxoD/EuN7MHw2O9bMEV5pjZjyy4D8hiM3tqLz52kgjJvvpPj9R9APV8ecXzQuAz4J5w2yPA2eHyZOC34fLrwIPh8lcIpykHfgV8K1zuSnB1ex5wOcEV4t3DbScAVQRXwkYIZkg9P9zWuE8kfJ1R4fpq4KdRcfeIWv4F8MNw+VGCeYYMmASUAocR/JCaT3ClahEwC8gLn/MffHmF9GrC6aPj2O+nzbynTxNMUthYj0LgCOCD8P3oQnDl7xiCad7rmsT4cFT8z4fH+TnBFcM5YVxrCL7cB0e9/5cDK8PXywY+BQbE8b4WRcW+Ojz+nuIdHe7/DF/+zdcTXoUNdE32Z1uP4KEWhOyLSg9utjLagxlLb4za9hBwRbh8BUHCaPQkgLvPAgrC89ZfBa6zYGrs1wm+pAaG+7/i7lujnv+eu6909/rwWMeG5ReEv8oXAIcQ3ASq0dNRy4ea2Ztm9gFwSbhvo3948C31AfCFu3/g7g0EX3KDCW5kNBKYHcZ6GTAoxnuzp/2ejvEcCCbBuy98f+rdvSSs39/cvdzdy4C/AseF+69qEuOMqPgHRx337+5e6e6bCeZPim5dNJrh7iXuXkUwj09jvC29r7HsKd6F4fL8qBgXA0+Y2bcIkoi0A/t8TlckFnefHZ5SOAGIuPuS6M1Ndyf41Xueu6+I3mBmRxFMXdx0/13WzWwIcC1wpLtvC08JZUftE32MRwlaN4vM7HKCVkmj6vDfhqjlxvV0glbTK+5+MS2zPezXtE57q2mM0fFH//+O9Z63dKx6ID2O93Vf4q0naNUAnEHQojwTuMHMDvMv7zMhSaIWhCTS48Bf2LX1AHAhgJkdC5SEv5KnAz80Mwu3jWnhuOMtmIE3LTzWW0ABwZduiZn1Ipjjvzn5wAYL+kguaWWd3gGOMbMDwzjzzOygcNuO8Nh72q8lM4Dvhc+JmFkh8CZwtpnlWjDz6DlhWWtMsuAe2T0IEuLcOJ/X0vsaXd9orYo3/DsOcPeZBKfiCglOTUmSKUFIIj1BMKPkk03Kq8xsAXA/X97D+BYgA1hsZkvD9ebMBe4hmDp7FcHpjEUEp0A+JEhKs1t4/n8T3Kludrh/3Nx9E8H5+ifNbDEwhy9vAjQFeMnMZu5hv5ZcDZwYnv6aD4x09/cJWj3vhXE/5O4LWhM3wSmcmQSJ6xZ3Xx/Pk/bwvu6sb5PntDbeCPDnsM4LgLtdo6HaBc3mKgljZucDk9z90qiy14Fr3X3eXh7zhPD5X98fMYpI89QHIQlhZr8nOB1xerJjEZG9oxaEiIjEpD4IERGJSQlCRERiUoIQEZGYlCBERCQmJQgREYnp/wM3tEFfFsV78QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot model performance and error\n",
    "\n",
    "results['mean_test_score'].plot(yerr=[results['std_test_score'], results['std_test_score']], subplots=True)\n",
    "\n",
    "plt.ylabel('Mean test score')\n",
    "plt.xlabel('Hyperparameter combinations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5390cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data score : 1.0\n",
      "Test data score : 0.9986772486772487\n"
     ]
    }
   ],
   "source": [
    "# get the predictions\n",
    "\n",
    "preds_train = search.predict_proba(X_train)[:,1]\n",
    "preds_test = search.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train data score : {}'.format(roc_auc_score(y_train, preds_train)))\n",
    "print('Test data score : {}'.format(roc_auc_score(y_test, preds_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a971ad8e",
   "metadata": {},
   "source": [
    "- Here we are getting a training score of 100%, so kind of over fitted with the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f60537c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_max_depth', 'param_min_samples_split', 'param_n_estimators',\n",
       "       'params', 'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
       "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1cd86fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the performance based on single hyper parameter\n",
    "\n",
    "def summarize_by_param(param):\n",
    "    tmp = pd.concat([\n",
    "        results.groupby(param)['mean_test_score'].mean(), \n",
    "        results.groupby(param)['mean_test_score'].std()\n",
    "        ], axis = 1)\n",
    "    tmp.columns = ['mean_test_score','std_test_score']\n",
    "    \n",
    "    return tmp    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d831415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.979546</td>\n",
       "      <td>0.003513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.984779</td>\n",
       "      <td>0.004880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.988068</td>\n",
       "      <td>0.002691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.989447</td>\n",
       "      <td>0.002949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean_test_score  std_test_score\n",
       "param_n_estimators                                 \n",
       "10                         0.979546        0.003513\n",
       "20                         0.984779        0.004880\n",
       "50                         0.988068        0.002691\n",
       "100                        0.989447        0.002949"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = summarize_by_param('param_n_estimators')\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c8c7eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'roc_auc')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp['mean_test_score'].plot(yerr=(temp['std_test_score'],temp['std_test_score']))\n",
    "plt.ylabel('roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2484b",
   "metadata": {},
   "source": [
    "The optimal hyperparameter seems to be somewhere between 60 and 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9afcc752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_max_depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.981967</td>\n",
       "      <td>0.006488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.986953</td>\n",
       "      <td>0.003601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.988069</td>\n",
       "      <td>0.004238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.986986</td>\n",
       "      <td>0.005052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mean_test_score  std_test_score\n",
       "param_max_depth                                 \n",
       "1                       0.981967        0.006488\n",
       "2                       0.986953        0.003601\n",
       "3                       0.988069        0.004238\n",
       "4                       0.986986        0.005052"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similary check for other params\n",
    "temp = summarize_by_param('param_max_depth')\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08f4909c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'roc_auc')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp['mean_test_score'].plot(yerr=(temp['std_test_score'],temp['std_test_score']))\n",
    "plt.ylabel('roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e72a6d6",
   "metadata": {},
   "source": [
    "- Optimal hyper param value lies somewhere between 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75b3d760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.985154</td>\n",
       "      <td>0.004976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.986135</td>\n",
       "      <td>0.004674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.985091</td>\n",
       "      <td>0.006079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean_test_score  std_test_score\n",
       "param_min_samples_split                                 \n",
       "0.1                             0.985154        0.004976\n",
       "0.3                             0.986135        0.004674\n",
       "0.5                             0.985091        0.006079"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarly for the last param\n",
    "temp = summarize_by_param('param_min_samples_split')\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2088ec2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'roc_auc')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEHCAYAAAC5u6FsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhsklEQVR4nO3de5hddX3v8fcnc08yMwnJ5AKBBAxWA6YqAQVKg7Q9Qj2KgKdKbY9YC7RHTm05nEc4WE6LWpTHVqVSNceiYq1g09rCEUwtl4MXoAQxCTEGkpRLroSYezKTZPI9f6zfnqzZM5PsFWZlT8jn9Tz7mbXXbX/XSmZ/5rd+a/+2IgIzM7Najap3AWZmdnRxcJiZWSEODjMzK8TBYWZmhTg4zMyskMZ6F3AkTJw4MWbMmFHvMszMjipPPvnkyxHRVT3/mAiOGTNmsHDhwnqXYWZ2VJH0/GDzfanKzMwKcXCYmVkhDg4zMyvEwWFmZoU4OMzMrBAHh5mZFeLgMDOzQhwcZmZWiIPDzOxV6L1ffpT3fvnRUvbt4DAzs0IcHGZmVoiDw8zMCnFwmJlZIQ4OMzMrxMFhVidl3vViViYHh5mZFeLgMDOzQhwcZmZWiIPDzMwKcXCYmVkhDg4zMyvEwWFmZoU4OMzMrBAHh5mZFVJqcEi6UNJySSskXT/I8umSHpC0WNLDkqblln1a0tPp8d7c/JMlPZ72ebek5jKPwczM+istOCQ1ALcDFwGzgMslzapa7TPAnRExG7gZuCVt+w7gzcAbgbcA10nqSNt8GvhsRMwENgMfKusYPCSEmdlAZbY4zgJWRMSqiNgD3AVcXLXOLODBNP1Qbvks4JGI2BcRO4HFwIWSBFwAzE/rfR14d3mHYGZm1coMjhOAF3PPV6d5eYuAS9P0JUC7pAlp/oWSRkuaCLwNOBGYAGyJiH0H2ScAkq6StFDSwo0bNw7LAZmZWf07x68D5kp6CpgLrAF6I+JfgfuAHwPfAh4FeovsOCLmRcSciJjT1dU1zGWbmR27ygyONWSthIppaV6fiFgbEZdGxJuAG9O8LennJyPijRHxG4CAZ4BNwDhJjUPt08zMylVmcDwBnJrugmoG3gfck19B0kRJlRpuAO5I8xvSJSskzQZmA/8aEUHWF/KetM0HgH8p8RjMzKxKacGR+iGuARYAy4BvR8RSSTdLelda7XxguaRngMnAJ9P8JuAHkn4GzAN+J9ev8VHgWkkryPo8/rasYzAzs4EaD73K4YuI+8j6KvLzbspNz+fAHVL5dbrJ7qwabJ+ryO7YMjOzOqh357iZmR1lHBxmZlaIg8PMzApxcJiZWSEODjMzK8TBYWZmhTg4zMysEAeHmZkV4uAwM7NCHBxmZlaIg8PMzApxcJiZWSEODjMzK8TBYWZmhTg4zMysEAeHmZkV4uAwM7NCHBxmZlaIg8PMzApxcJiZWSEODjMzK8TBYWZmhTg4zMysEAeHmZkVUmpwSLpQ0nJJKyRdP8jy6ZIekLRY0sOSpuWW3SppqaRlkm6TpDT/cklL0jbfkzSxzGMwM7P+SgsOSQ3A7cBFwCzgckmzqlb7DHBnRMwGbgZuSdueA5wLzAZOB84E5kpqBD4PvC1tsxi4pqxjMDOzgcpscZwFrIiIVRGxB7gLuLhqnVnAg2n6odzyAFqBZqAFaAI2AEqPMakF0gGsLfEYzMysSpnBcQLwYu756jQvbxFwaZq+BGiXNCEiHiULknXpsSAilkXEXuAPgSVkgTEL+NvBXlzSVZIWSlq4cePG4TomM7NjXr07x68juwT1FDAXWAP0SpoJvB6YRhY2F0g6T1ITWXC8CTie7FLVDYPtOCLmRcSciJjT1dV1BA7FzOzY0FjivtcAJ+aeT0vz+kTEWlKLQ9JY4LKI2CLpSuCxiNiRlt0PnA10p+1WpvnfBgZ0upuZWXnKbHE8AZwq6WRJzcD7gHvyK0iaKKlSww3AHWn6BVJneGplzAWWkQXPLEmVJsRvpPlmZnaElNbiiIh9kq4BFgANwB0RsVTSzcDCiLgHOB+4RVIAjwAfTpvPBy4g68sI4HsRcS+ApD8HHpG0F3geuKKsYzAzs4HKvFRFRNwH3Fc176bc9HyykKjerhe4eoh9fgn40vBWamZmtap357iZmR1lHBxmZlaIg8PMzApxcJiZWSEODjMzK8TBYWZmhTg4zMysEAeHmZkV4uAwM7NCHBxmZlaIg8PMzApxcJiZWSEODjMzK8TBYWZmhTg4zMysEAeHmZkV4uAwM7NCHBxmZlaIg8PMzApxcJiZWSEODjMzK8TBYWZmhTg4zMyskMYydy7pQuDzQAPwlYj4VNXy6cAdQBfwC+B3ImJ1WnYr8A6ycPs+8JGICEnNwBeA84H9wI0R8Y9lHofZKxURbN61lw3bulm/rZsNW7tZvXk3QfDNx59namcrUzvbmNrZSmdbE5LqXbLZkEoLDkkNwO3AbwCrgSck3RMRP8ut9hngzoj4uqQLgFuA35V0DnAuMDut90NgLvAwcCPwUkS8VtIo4LiyjsGsFt17e3lpWw/rc6HQFxB9P3vYs2//oNvf+J2n+z1va2pg6rjWfmHS93NcK1M72uhoa3S4WN0cMjgk/QVwa0RsSc/HA/8jIj52iE3PAlZExKq03V3AxUA+OGYB16bph4B/TtMBtALNgIAmYENa9nvA6wAiYj/w8qGOwexw7N8f/GLXHtZv7eal7d2s39rTFwyVUNiwrZvNu/YO2La1aRRTOlqZ3NHKm08a3zc9pbOVyR0tTO5o5U/u/ikCPn/5m1i3tZt1W7pZt3V3Np1+/vDZl3lpezf7o//+Rzc3VAVLK1PHtTGls5XjO7OfHa0OFytHLS2OiyLif1WeRMRmSb8JHCo4TgBezD1fDbylap1FwKVkl7MuAdolTYiIRyU9BKwjC44vRMQySePSdh+XdD6wErgmIjZU7RdJVwFXAZx00kk1HKYdS7r39rI+FwDrt2atgkoLoRIWe3v7v2NLMHFsC1M6Wpk2fjRzZoxncnsrkztbmdIXDLW9aY9Ky7M3/zYY4r/pvt79vLS950CgbOnuFy6PPLuRl7b3EFXhMqa5ganjDgTLlM42ju/Majw+zW9vbTrsc2jHrlqCo0FSS0T0AEhqA1qG6fWvA74g6QrgEWAN0CtpJvB6YFpa7/uSzgOWpXk/johrJV1Ldrnrd6t3HBHzgHkAc+bMierl9uq0f3/w8s4eNmzt6X+5qF8roYetuwe2EsY0N/QFwFknH5e1EDpa+sJgckcrXe0tNDUc2XtKGhtGcfy4No4f1waMH3SdvSlc1m/dzdp8y2VLN+u2dbN8/UY27hgYLmNbGlOoHGipHD8uf2msjbEtpXaF2lGolv8R3wQekPTV9PyDwNdr2G4NcGLu+bQ0r09ErCVrcSBpLHBZRGyRdCXwWETsSMvuB84m6+vYBfxT2sU/AB+qoRZ7Fdi1Z19VK6Gn73JR5RLSS9t72Fd1XWeUoKs9ayXMmDCGt54yIYVC5fJRdunoaP7ru6lhFCeMa+OEcW2cMX3wdfb27u8L0bVbu1m35cBlsfVbu/n5+u28PEi4tLc0MnVcVYuls61fP8wYh8sx5ZD/2hHxaUmLgV9Lsz4eEQtq2PcTwKmSTiYLjPcBv51fQdJE4Bepr+IGsjusAF4ArpR0C9mlqrnA59JdVfeS3VH1YKop32diR6He/cHLO3r6QuGlvstFPf1CYXvPvgHbtrc09rUSzn7NRCbnWgiVS0cTx7bQMMrX+psaRjFt/GimjR895Dp79mXhkr8Utn5rN2u37Gb9tm5+tnYbL+/oGbBde2tjvxbLlI4sWPLzRjc7XF4tavqXjIj7gfuL7Dgi9km6BlhAdjvuHRGxVNLNwMKIuIcsAG6RFGSXqj6cNp8PXAAsIeso/15E3JuWfRT4hqTPARvJWkA2Qm3v3nug76C6T2F7Dxu2drNxRw+9Va2ExlFiUnsLkzpamdk1ll+ZObFf66ASDP5Ld3g1N47ixONGc+Jxhw6XSpis3dKdXSJLIbN07VZe3rFnwHYdrY0cnzrw8536B+Y5XI4WtdxVtZ3szRuyu5yagJ0R0XGobSPiPuC+qnk35abnk4VE9Xa9wNVD7PN54FcP9dpWrn29+9mYWgnVQZC/LXXnnt4B23a0Nva1Cl47aSJTOluZVGkhdLQyubOFCWPcShipagmXnn29bNjaw9p0Gazv55Zu1m/bzZLVW9m0c2C4dLY19btLbGpH9rNyiWxqZxttzQ1lHp7VoJZLVe2VaWW3iVwMvLXMoqx+IoJt3fsO9B3kPpOQ71N4eUfPgFtEmxrEpPbsF/x1U9qZ+9qufncaVfoU/Iv/6tfS2MBJE0Zz0oShw6V7b29quWRhkrVcDlwiW7R6K78YJFzGjW7qfxtypQWT69RvbfL/sTIVahdGRAD/LOl/A9eXU5KV5cCdN/1DIf8htfVbu9m9d2ArYdzopr43/llTO/r6FSqfSZjS2cpxo5sZ5VaC1ai1qYHpE8YwfcKYIdep3DZdabFU35L81AubB/0czfh8uIwb+EHKKQ6XV6SWS1WX5p6OAuYA3aVVZIVFBFt37+1786++XFSZv2nnwDtmmhtHZR3KHa2cdnwHv/a6SVkfQueBS0eTOlr8S2Z10drUwIyJY5gx8eDhsq7qLrF1KWTWbu3myRc2s2WQcDluTHO/Fkv1rchTOltpafT/+8HU0uJ4Z256H/Ac2eUqOwJ69mXDWeQ/mFb5LEL+08vdewcOZzFhTHPqSG5h9rTOA5eLOg9cNho/2uMi2dGttamBkyeO4eSDhMvuPb39AmXdlt2s25b9XL15N088t3nQz/ZMGNOc3Yrc0ZbdLVa5FTmFzeTOlmMyXGrp4/BdSyWoDHo38HJR5e6jLCwGu8bb0jiqr9/gl6eNy31AraUvECZ1HJv/oc0G09bcwCldYzmla+yQ6+zas2+QoV+y6dWbd/Hv/7GJbd0DbwmfOLb5QIul8gn9XMtlckcrzY2vroHIa7lU1Ur2IbvTyMaPAiAifq/Euo5qgw16V5l+KdefUD3onQQTxrQwpbOFE8a18qaTxuXuNDpw6cgD3JkNv9HNjbymayyvOUi47OzZ1/9yWK5j/4VNu3hs1Sa2DxouLenzLf1vPz5+XFvfH3tHU7jUcqnqG8DPgbcDNwPvJxv645iTH/Qu36GcH/Ru/bbuQa+ntjU19A1wd8ZJ46v6ELIm8KQ6DGdhZrUb09LIzEljmTlp6HDZ0bOvb+iXfrcib+3muU07eXTlpgEfZq2MgZa/7bhyS3Jl3uSO1hHz/lBLcMyMiP8i6eI0/PnfAz8ou7CRYPXmXeze08ulf/MjNmzrGXTQu1GVQe86WznxuNGcOeO4fncaVVoL7S1uJZgdC8a2NDJzUjszJ7UPuc727r19YVIdMis37uSHz7484DNQEnSNbcl9vuVAx/7xaUiYye0tNB6BcKklOCp/Pm+RdDqwHphUXkkjx7bufezt3U9rUwNvOfm4fp3KlVCYOLb5iPxDmdmrR3trE+2tTZw6eehw2VYJly27+4XMuq3dPPvSdh55diO7qsKlMi7b1M42nt+0k5bGUezas2/YP5Ffy97mpe/g+BhwDzAW+NNhrWKEmjU1+3D831/pzzua2ZHV0dpER2sTrx0iXCof1u33OZctBzr1d+/tZdvufTSX8IdtLXdVfSVNPgKcUr1c0gciopbRcs3MbJhIorOtic62Jn5pysBwee+XHyUiSrkiMhx7/Mgw7MPMzIZZWf2qwxEc7vE1MzuGDEdw+Nv1zMyOIW5xmJlZIcMRHD8ahn2YmdlR4pDBIekvJI3LPR8v6ROV5xFxTUm1mZnZCFRLi+OiiNhSeRIRm4HfLK0iMzMb0WoJjgZJLZUnktqAloOsb2Zmr2K1fHL8m8ADkr6ann8Q8Af+zMyOUbV8cvzTkhYBv55mfTwiFpRblpmZjVS1jnz1FNBE9pmNp8orx8zMRrpa7qr6LeDfgfcAvwU8Luk9ZRdmZmYjUy0tjhuBMyPiJQBJXcC/AfPLLMzMzEamWu6qGlUJjWRTjdsh6UJJyyWtkHT9IMunS3pA0mJJD0uallt2q6SlkpZJuk1Vo3VJukfS07XUYWZmw+egAZDerJ+QtEDSFZKuAL4L3HeoHUtqAG4HLgJmAZdLmlW12meAOyNiNtnX0t6Stj0HOBeYDZwOnAnMze37UmBHLQdoZmbD66DBEREBnAV8mexNfDYwLyI+WsO+zwJWRMSqiNgD3AVcXLXOLODBNP1QbnkArUAz2WdGmoANAJLGAtcCn8DMzI64Wvo4ngRejIhrC+77BODF3PPVwFuq1lkEXAp8HrgEaJc0ISIelfQQsI5sEMUvRMSytM3Hgb8Edh3sxSVdBVwFcNJJJxUs3czMhlJLX8VbgEclrUx9EYslLR6m178OmCvpKbJLUWuAXkkzgdcD08gC6AJJ50l6I/CaiPjOoXYcEfMiYk5EzOnq6hqmcs3MrJYWx9sPc99rgBNzz6eleX0iYi1Zi6NyCeqyiNgi6UrgsYjYkZbdD5wNbAfmSHou1T5J0sMRcf5h1mhmZgUdssUREc8P9qhh308Ap0o6WVIz8D7gnvwKkiZKqtRwA3BHmn6BrCXSKKmJrDWyLCK+GBHHR8QM4FeAZxwaZmZH1vB/i3kSEfuAa4AFwDLg2xGxVNLNkt6VVjsfWC7pGWAy8Mk0fz6wElhC1g+yKCLuLatWMzOrXa1DjhyWiLiPqlt3I+Km3PR8BvkgYUT0AlcfYt/Pkd2qa2ZmR1BpLQ4zM3t1cnCYmVkhDg4zMyvEwWFmZoU4OMzMrBAHh5mZFeLgMDOzQhwcZmZWiIPDzMwKcXCYmVkhDg4zMyvEwWFmZoU4OMzMrBAHh5mZFeLgMDOzQhwcZmZWiIPDzMwKcXCYmVkhDg4zMyvEwWFmZoU4OMzMrBAHh5mZFeLgMDOzQkoNDkkXSlouaYWk6wdZPl3SA5IWS3pY0rTcslslLZW0TNJtyoyW9F1JP0/LPlVm/WZmNlBpwSGpAbgduAiYBVwuaVbVap8B7oyI2cDNwC1p23OAc4HZwOnAmcDcyjYR8TrgTcC5ki4q6xjMzGygMlscZwErImJVROwB7gIurlpnFvBgmn4otzyAVqAZaAGagA0RsSsiHgJI+/wJMA0zMztiygyOE4AXc89Xp3l5i4BL0/QlQLukCRHxKFmQrEuPBRGxLL+hpHHAO4EHBntxSVdJWihp4caNG1/psZiZWVLvzvHrgLmSniK7FLUG6JU0E3g9WWviBOACSedVNpLUCHwLuC0iVg2244iYFxFzImJOV1dX2cdhZnbMaCxx32uAE3PPp6V5fSJiLanFIWkscFlEbJF0JfBYROxIy+4HzgZ+kDadBzwbEZ8rsX4zMxtEmS2OJ4BTJZ0sqRl4H3BPfgVJEyVVargBuCNNv0DWEmmU1ETWGlmWtvkE0An8cYm1m5nZEEoLjojYB1wDLCB70/92RCyVdLOkd6XVzgeWS3oGmAx8Ms2fD6wElpD1gyyKiHvT7bo3knWq/0TSTyX9flnHYGZmA5V5qYqIuA+4r2reTbnp+WQhUb1dL3D1IPNXAxr+Ss3MrFb17hw3M7OjjIPDzMwKcXCYmVkhpfZxmNnQ7r767HqXYHZY3OIwM7NCHBxmZlaIg8PMzApxcJiZWSEODjMzK8TBYWZmhTg4zMysEAeHmZkV4uAwM7NCHBxmZlaIg8PMzApxcJiZWSEODjMzK8TBYWZmhTg4zMysEAeHmZkV4uAwM7NCHBxmZlaIg8PMzApxcJiZWSGlBoekCyUtl7RC0vWDLJ8u6QFJiyU9LGlabtmtkpZKWibpNklK88+QtCTts29+Ge6++mzuvvrssnZvZnZUKi04JDUAtwMXAbOAyyXNqlrtM8CdETEbuBm4JW17DnAuMBs4HTgTmJu2+SJwJXBqelxY1jGYmdlAZbY4zgJWRMSqiNgD3AVcXLXOLODBNP1QbnkArUAz0AI0ARskTQU6IuKxiAjgTuDdJR6DmZlVKTM4TgBezD1fneblLQIuTdOXAO2SJkTEo2RBsi49FkTEsrT96kPsEwBJV0laKGnhxo0bX/HBmJlZpt6d49cBcyU9RXYpag3QK2km8HpgGlkwXCDpvCI7joh5ETEnIuZ0dXUNd91mZsesxhL3vQY4Mfd8WprXJyLWklocksYCl0XEFklXAo9FxI607H7gbOAbaT9D7tPMzMpVZovjCeBUSSdLagbeB9yTX0HSREmVGm4A7kjTL5C1RBolNZG1RpZFxDpgm6S3prup/ivwLyUeg5mZVSktOCJiH3ANsABYBnw7IpZKulnSu9Jq5wPLJT0DTAY+mebPB1YCS8j6QRZFxL1p2X8DvgKsSOvcX9YxmJnZQGVeqiIi7gPuq5p3U256PllIVG/XC1w9xD4Xkt2ia2ZmdVDvznEzMzvKODjMzKwQB4eZmRXi4DAzs0IcHGZmVoiDw8zMCnFwmJlZIQ4OMzMrxMFhZmaFODjMzKyQUoccMTOz+ijza6/d4jAzs0IcHGZmVoiDw8zMCnFwmJlZIQ4OMzMrxMFhZmaFODjMzKwQB4eZmRXi4DAzs0IUEfWuoXSSNgLPH+bmE4GXh7Gc4eK6inFdxbiuYl6tdU2PiK7qmcdEcLwSkhZGxJx611HNdRXjuopxXcUca3X5UpWZmRXi4DAzs0IcHIc2r94FDMF1FeO6inFdxRxTdbmPw8zMCnGLw8zMCnFwmJlZIcdscEi6UNJySSskXT/I8l+V9BNJ+yS9p2rZByQ9mx4fGEF19Ur6aXrcM5x11VjbtZJ+JmmxpAckTc8tq+c5O1hdpZ2zGur6A0lL0mv/UNKs3LIb0nbLJb19JNQlaYak3bnz9aUjWVduvcskhaQ5uXl1O19D1VXv8yXpCkkbc6//+7llr+z3MSKOuQfQAKwETgGagUXArKp1ZgCzgTuB9+TmHwesSj/Hp+nx9a4rLdtR53P2NmB0mv5D4O4Rcs4GravMc1ZjXR256XcB30vTs9L6LcDJaT8NI6CuGcDT9Tpfab124BHgMWDOSDhfB6mrrucLuAL4wiDbvuLfx2O1xXEWsCIiVkXEHuAu4OL8ChHxXEQsBvZXbft24PsR8YuI2Ax8H7hwBNRVtlpqeygidqWnjwHT0nS9z9lQdZWplrq25Z6OASp3qlwM3BURPRHxH8CKtL9611WmQ9aVfBz4NNCdm1fX83WQuspUa12DecW/j8dqcJwAvJh7vjrNK3vbsvfdKmmhpMckvXuYaqooWtuHgPsPc9sjVReUd85qqkvShyWtBG4F/qjItnWoC+BkSU9J+n+SzhummmqqS9KbgRMj4rtFt61TXVDH85Vcli7Rzpd0YsFth9RYZGUb8aZHxBpJpwAPSloSESuPdBGSfgeYA8w90q99MEPUVddzFhG3A7dL+m3gY8Cw9v8criHqWgecFBGbJJ0B/LOk06paKKWQNAr4K7LLLyPGIeqq2/lK7gW+FRE9kq4Gvg5cMBw7PlZbHGuAE3PPp6V5ZW9b6r4jYk36uQp4GHjTMNVVc22Sfh24EXhXRPQU2bYOdZV5zooe813Auw9z2yNSV7oUtClNP0l2jf21R6iuduB04GFJzwFvBe5JHdH1PF9D1lXn80VEbMr9X/8KcEat2x5SGR03I/1B1tJaRdaRVulYOm2Idb/GwM7x/yDrVBqfpo8bAXWNB1rS9ETgWQbpxCuzNrI33ZXAqVXz63rODlJXaeesxrpOzU2/E1iYpk+jf2fvKoavs/eV1NVVqYOsU3ZNPf7vp/Uf5kAndF3P10Hqquv5Aqbmpi8BHkvTr/j38RUfwNH6AH4TeCa9odyY5t1M9hcpwJlk1/52ApuApbltf4+sA24F8MGRUBdwDrAk/QdaAnyoDufs34ANwE/T454Rcs4Gravsc1ZDXZ8HlqaaHsr/4pO1jlYCy4GLRkJdwGW5+T8B3nkk66pa92HSG3S9z9dQddX7fAG3pNdflP4dX5fb9hX9PnrIETMzK+RY7eMwM7PD5OAwM7NCHBxmZlaIg8PMzApxcJiZWSEODjMzK8TBYXaYJB0vaX696zgUSV9T1RD8R/C1n5M0MU3/OP2ckYYysaOUg8OOapLqNt5aRKyNiLq8IR+NIuKcNDkDcHAcxRwcVnfpL9CfS/qmpGVpJM/Rkm6S9ISkpyXNk6S0/sOSPidpIfARSe+U9HgahfTfJE1O6/2ZpK9L+oGk5yVdKulWZV9S9D1JTQep6TlJt6QvwFko6c2SFkhaKekPcnU/naavkPRPab/PSrr1IPtuSK2Ap1Mtf5LmX5mOd5Gkf5Q0Os3/mqQvphF8V0k6X9Id6Vx9LbffHZI+K2mpsi+s6hrktc9II7U+mY5napr/RzrwZVd3HaT2uTrwxUBPSWpP9Twi6bvKvljoS2nwv+ptd6TJTwHnpX38yVCvZSPYcH4E3g8/DudB9hdoAOem53cA15EbPwf4BmnIBrJhHf4mt2w89I2C8PvAX6bpPwN+CDQBvwzsIg1HAXwHePdBanoO+MM0/VlgMdmAdl3AhlzdT6fpK8jGDuoEWoHnyYbaHmzfZ5B9H0Ll+bj0c0Ju3ieA/56mv0Y22KDIvnNhG/AGsj/8ngTemNYL4P1p+ibSl/ik7d+TzsOPga40/73AHWl6LQfG7Rp3kPNyb+7faSzZmEnnk30PxSlkXzD0fdI4auk8TkzTO9LP84H/W+//d34c/sMtDhspXoyIH6XpvwN+BXhbakksIRsO+rTc+nfnpqcBC9J6/7NqvfsjYi/ZWFQNwPfS/CVkb/wHU/kq2SXA4xGxPSI2Aj2Sxg2y/gMRsTUiuoGfAdOH2O8q4BRJfy3pQrIgADg9tY6WAO+vOo57I3vXXUIWXEsiYj/ZWESV49jPgfNSOYd5v0Q2kuv3Jf2UbLj0ypdaLQa+qWzo+X1D1A3wI+CvJP0RWcBU1v33yL5UqBf41iCvba8iDg4bKaoHTQvgb8j+cn0D8H/I/pKv2Jmb/muyv67fAFxdtV4PQHqT3ZvefCF7kz1U/0hlSOr9uemDbZtfp3eo/Uf2rWu/TNZy+gOyIa8haxlck47jzwc7jgK1wMBzKrJBMd+YHm+IiP+Ulr0DuB14M/DEUH1HEfEpslZdG/AjSa8b4rU8CN6rmIPDRoqTJJ2dpn+b7BITwMuSxpJdahlKJwe+T+ADJdU3bNJdRqMi4h/J/up/c1rUDqxLfS/vP4xdj+LAecqfw4rlQFflPEtqknRa6o84MSIeAj5Kdj7HDlH7a1Jr59PAE0AlOM6SdHLa13sHee287WTHakcpfwOgjRTLgQ9LuoPsMs8XyfoungbWk71JDeXPgH+QtBl4kOw7CkayE4Cv5jqQb0g//xR4HNiYfhZ9c91J9gb+MeAlsjfwPhGxR9ltubdJ6iT7/f8c2dDcf5fmCbgtIrYM8Rp/LOltZC2dpWRfw3s22b/PF4CZZEN4f+cgdS4GeiUtAr4WEZ8teJxWZx5W3epO0gyyztLT613L0UzSjogYtKVQ8uueD1wXEf/5SL+21YcvVZmZWSFucdgxTdJ3GHhp66MRsWCY9v842Vea5v1uRCwZjv2XRdIHgY9Uzf5RRHy4HvXYyOLgMDOzQnypyszMCnFwmJlZIQ4OMzMrxMFhZmaF/H8OM0F1baxbYwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp['mean_test_score'].plot(yerr=(temp['std_test_score'],temp['std_test_score']))\n",
    "plt.ylabel('roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2150257",
   "metadata": {},
   "source": [
    "- This one doesnt seem to have much impact on the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "494ebed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=0),\n",
       "             param_grid={'loss': ['deviance', 'exponential'],\n",
       "                         'max_depth': [2, 3],\n",
       "                         'n_estimators': [60, 80, 100, 120, 140]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets deep dive for other hyper param space \n",
    "# knowing the n_estimators might lie between 60-100 and\n",
    "# max depth between 2 and 3\n",
    "\n",
    "# determine the hyperparameter space\n",
    "param_grid = dict(\n",
    "    n_estimators=[60, 80, 100, 120, 140],\n",
    "    max_depth=[2,3],\n",
    "    loss = ['deviance', 'exponential'], # adding additional hyper parameter\n",
    "    )\n",
    "\n",
    "# set up the search\n",
    "search = GridSearchCV(gbm, param_grid, scoring='roc_auc', cv=5, refit=True)\n",
    "\n",
    "# find best hyperparameters\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72ffcfcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 'exponential', 'max_depth': 2, 'n_estimators': 140}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43b3664f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.102622</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>{'loss': 'deviance', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.991333</td>\n",
       "      <td>0.995172</td>\n",
       "      <td>0.991156</td>\n",
       "      <td>0.991066</td>\n",
       "      <td>0.006638</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>{'loss': 'deviance', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.978333</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.994483</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>0.990797</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.168798</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'loss': 'deviance', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979667</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.995172</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.992149</td>\n",
       "      <td>0.006904</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.204596</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>{'loss': 'deviance', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980333</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.995862</td>\n",
       "      <td>0.995918</td>\n",
       "      <td>0.992556</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.232407</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>deviance</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>{'loss': 'deviance', 'max_depth': 2, 'n_estima...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.995862</td>\n",
       "      <td>0.995238</td>\n",
       "      <td>0.992553</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.141799</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>deviance</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>{'loss': 'deviance', 'max_depth': 3, 'n_estima...</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.992667</td>\n",
       "      <td>0.992414</td>\n",
       "      <td>0.988435</td>\n",
       "      <td>0.989237</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.192397</td>\n",
       "      <td>0.006523</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>deviance</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>{'loss': 'deviance', 'max_depth': 3, 'n_estima...</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.974000</td>\n",
       "      <td>0.992667</td>\n",
       "      <td>0.994483</td>\n",
       "      <td>0.989116</td>\n",
       "      <td>0.989653</td>\n",
       "      <td>0.008335</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.236821</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>deviance</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'loss': 'deviance', 'max_depth': 3, 'n_estima...</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.974333</td>\n",
       "      <td>0.992667</td>\n",
       "      <td>0.995172</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.990130</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.285611</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>deviance</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>{'loss': 'deviance', 'max_depth': 3, 'n_estima...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.973667</td>\n",
       "      <td>0.992667</td>\n",
       "      <td>0.995172</td>\n",
       "      <td>0.991156</td>\n",
       "      <td>0.990266</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.332606</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>deviance</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>{'loss': 'deviance', 'max_depth': 3, 'n_estima...</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.974333</td>\n",
       "      <td>0.992667</td>\n",
       "      <td>0.995172</td>\n",
       "      <td>0.992517</td>\n",
       "      <td>0.990805</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.101796</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>exponential</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>{'loss': 'exponential', 'max_depth': 2, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.991210</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.136015</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>exponential</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>{'loss': 'exponential', 'max_depth': 2, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.988667</td>\n",
       "      <td>0.999310</td>\n",
       "      <td>0.992517</td>\n",
       "      <td>0.992765</td>\n",
       "      <td>0.006340</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.167016</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>exponential</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'loss': 'exponential', 'max_depth': 2, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983667</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.998621</td>\n",
       "      <td>0.992517</td>\n",
       "      <td>0.992828</td>\n",
       "      <td>0.006021</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.199011</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>exponential</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>{'loss': 'exponential', 'max_depth': 2, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982333</td>\n",
       "      <td>0.991333</td>\n",
       "      <td>0.997931</td>\n",
       "      <td>0.993878</td>\n",
       "      <td>0.993095</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.237604</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.002396</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>exponential</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>{'loss': 'exponential', 'max_depth': 2, 'n_est...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982000</td>\n",
       "      <td>0.991333</td>\n",
       "      <td>0.997931</td>\n",
       "      <td>0.994558</td>\n",
       "      <td>0.993164</td>\n",
       "      <td>0.006315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.142389</td>\n",
       "      <td>0.001030</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>exponential</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>{'loss': 'exponential', 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.998000</td>\n",
       "      <td>0.973667</td>\n",
       "      <td>0.988667</td>\n",
       "      <td>0.993793</td>\n",
       "      <td>0.989796</td>\n",
       "      <td>0.988784</td>\n",
       "      <td>0.008241</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.204010</td>\n",
       "      <td>0.019070</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>exponential</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>{'loss': 'exponential', 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.972667</td>\n",
       "      <td>0.990667</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.989944</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.257179</td>\n",
       "      <td>0.016383</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>exponential</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'loss': 'exponential', 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.992667</td>\n",
       "      <td>0.998621</td>\n",
       "      <td>0.991156</td>\n",
       "      <td>0.990422</td>\n",
       "      <td>0.010178</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.311406</td>\n",
       "      <td>0.010540</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>exponential</td>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "      <td>{'loss': 'exponential', 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.972333</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>0.991837</td>\n",
       "      <td>0.990682</td>\n",
       "      <td>0.009506</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.365794</td>\n",
       "      <td>0.010304</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>exponential</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>{'loss': 'exponential', 'max_depth': 3, 'n_est...</td>\n",
       "      <td>0.998667</td>\n",
       "      <td>0.973667</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.997241</td>\n",
       "      <td>0.993878</td>\n",
       "      <td>0.991357</td>\n",
       "      <td>0.009069</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time   param_loss  \\\n",
       "0        0.102622      0.003895         0.002186        0.000407     deviance   \n",
       "1        0.134615      0.001009         0.002369        0.000492     deviance   \n",
       "2        0.168798      0.001956         0.002201        0.000401     deviance   \n",
       "3        0.204596      0.003493         0.002596        0.000511     deviance   \n",
       "4        0.232407      0.001190         0.001993        0.000011     deviance   \n",
       "5        0.141799      0.000759         0.002601        0.000490     deviance   \n",
       "6        0.192397      0.006523         0.002394        0.000480     deviance   \n",
       "7        0.236821      0.003111         0.002179        0.000401     deviance   \n",
       "8        0.285611      0.004166         0.002181        0.000382     deviance   \n",
       "9        0.332606      0.002508         0.002393        0.000496     deviance   \n",
       "10       0.101796      0.000748         0.002197        0.000402  exponential   \n",
       "11       0.136015      0.002700         0.002385        0.000503  exponential   \n",
       "12       0.167016      0.000653         0.002192        0.000404  exponential   \n",
       "13       0.199011      0.000618         0.002188        0.000405  exponential   \n",
       "14       0.237604      0.003940         0.002396        0.000494  exponential   \n",
       "15       0.142389      0.001030         0.002604        0.000502  exponential   \n",
       "16       0.204010      0.019070         0.002590        0.000521  exponential   \n",
       "17       0.257179      0.016383         0.002407        0.000496  exponential   \n",
       "18       0.311406      0.010540         0.002801        0.000745  exponential   \n",
       "19       0.365794      0.010304         0.002198        0.000403  exponential   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "0                2                 60   \n",
       "1                2                 80   \n",
       "2                2                100   \n",
       "3                2                120   \n",
       "4                2                140   \n",
       "5                3                 60   \n",
       "6                3                 80   \n",
       "7                3                100   \n",
       "8                3                120   \n",
       "9                3                140   \n",
       "10               2                 60   \n",
       "11               2                 80   \n",
       "12               2                100   \n",
       "13               2                120   \n",
       "14               2                140   \n",
       "15               3                 60   \n",
       "16               3                 80   \n",
       "17               3                100   \n",
       "18               3                120   \n",
       "19               3                140   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'loss': 'deviance', 'max_depth': 2, 'n_estima...           0.998667   \n",
       "1   {'loss': 'deviance', 'max_depth': 2, 'n_estima...           0.999333   \n",
       "2   {'loss': 'deviance', 'max_depth': 2, 'n_estima...           1.000000   \n",
       "3   {'loss': 'deviance', 'max_depth': 2, 'n_estima...           1.000000   \n",
       "4   {'loss': 'deviance', 'max_depth': 2, 'n_estima...           1.000000   \n",
       "5   {'loss': 'deviance', 'max_depth': 3, 'n_estima...           0.998000   \n",
       "6   {'loss': 'deviance', 'max_depth': 3, 'n_estima...           0.998000   \n",
       "7   {'loss': 'deviance', 'max_depth': 3, 'n_estima...           0.998000   \n",
       "8   {'loss': 'deviance', 'max_depth': 3, 'n_estima...           0.998667   \n",
       "9   {'loss': 'deviance', 'max_depth': 3, 'n_estima...           0.999333   \n",
       "10  {'loss': 'exponential', 'max_depth': 2, 'n_est...           1.000000   \n",
       "11  {'loss': 'exponential', 'max_depth': 2, 'n_est...           1.000000   \n",
       "12  {'loss': 'exponential', 'max_depth': 2, 'n_est...           1.000000   \n",
       "13  {'loss': 'exponential', 'max_depth': 2, 'n_est...           1.000000   \n",
       "14  {'loss': 'exponential', 'max_depth': 2, 'n_est...           1.000000   \n",
       "15  {'loss': 'exponential', 'max_depth': 3, 'n_est...           0.998000   \n",
       "16  {'loss': 'exponential', 'max_depth': 3, 'n_est...           0.998667   \n",
       "17  {'loss': 'exponential', 'max_depth': 3, 'n_est...           0.998667   \n",
       "18  {'loss': 'exponential', 'max_depth': 3, 'n_est...           0.998667   \n",
       "19  {'loss': 'exponential', 'max_depth': 3, 'n_est...           0.998667   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.979000           0.991333           0.995172   \n",
       "1            0.978333           0.990000           0.994483   \n",
       "2            0.979667           0.990667           0.995172   \n",
       "3            0.980333           0.990667           0.995862   \n",
       "4            0.981000           0.990667           0.995862   \n",
       "5            0.974667           0.992667           0.992414   \n",
       "6            0.974000           0.992667           0.994483   \n",
       "7            0.974333           0.992667           0.995172   \n",
       "8            0.973667           0.992667           0.995172   \n",
       "9            0.974333           0.992667           0.995172   \n",
       "10           0.979000           0.989333           0.997241   \n",
       "11           0.983333           0.988667           0.999310   \n",
       "12           0.983667           0.989333           0.998621   \n",
       "13           0.982333           0.991333           0.997931   \n",
       "14           0.982000           0.991333           0.997931   \n",
       "15           0.973667           0.988667           0.993793   \n",
       "16           0.972667           0.990667           0.997241   \n",
       "17           0.971000           0.992667           0.998621   \n",
       "18           0.972333           0.993333           0.997241   \n",
       "19           0.973667           0.993333           0.997241   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.991156         0.991066        0.006638               10  \n",
       "1            0.991837         0.990797        0.006979               12  \n",
       "2            0.995238         0.992149        0.006904                7  \n",
       "3            0.995918         0.992556        0.006791                5  \n",
       "4            0.995238         0.992553        0.006491                6  \n",
       "5            0.988435         0.989237        0.007894               19  \n",
       "6            0.989116         0.989653        0.008335               18  \n",
       "7            0.990476         0.990130        0.008288               16  \n",
       "8            0.991156         0.990266        0.008680               15  \n",
       "9            0.992517         0.990805        0.008597               11  \n",
       "10           0.990476         0.991210        0.007305                9  \n",
       "11           0.992517         0.992765        0.006340                4  \n",
       "12           0.992517         0.992828        0.006021                3  \n",
       "13           0.993878         0.993095        0.006174                2  \n",
       "14           0.994558         0.993164        0.006315                1  \n",
       "15           0.989796         0.988784        0.008241               20  \n",
       "16           0.990476         0.989944        0.009259               17  \n",
       "17           0.991156         0.990422        0.010178               14  \n",
       "18           0.991837         0.990682        0.009506               13  \n",
       "19           0.993878         0.991357        0.009069                8  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf is basically a dictionary that returns the scores and other cross validation results\n",
    "results = pd.DataFrame(search.cv_results_)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3724d47",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['param_min_samples_split'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m results\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m results\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparam_max_depth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparam_min_samples_split\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparam_n_estimators\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_test_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstd_test_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3464\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3463\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3464\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3466\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1314\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 1314\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_read_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_i8_conversion(ax\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   1317\u001b[0m     ax, (IntervalIndex, CategoricalIndex)\n\u001b[0;32m   1318\u001b[0m ):\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;66;03m# For CategoricalIndex take instead of reindex to preserve dtype.\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;66;03m#  For IntervalIndex this is to map integers to the Intervals they match to.\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexing.py:1377\u001b[0m, in \u001b[0;36m_LocIndexer._validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1376\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 1377\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['param_min_samples_split'] not in index\""
     ]
    }
   ],
   "source": [
    "# we can order the different models based on their performance\n",
    "results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
    "\n",
    "results.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8c93a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_loss', 'param_max_depth', 'param_n_estimators', 'params',\n",
       "       'split0_test_score', 'split1_test_score', 'split2_test_score',\n",
       "       'split3_test_score', 'split4_test_score', 'mean_test_score',\n",
       "       'std_test_score', 'rank_test_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1f7af62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>exponential</td>\n",
       "      <td>140</td>\n",
       "      <td>0.993164</td>\n",
       "      <td>0.006315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>exponential</td>\n",
       "      <td>120</td>\n",
       "      <td>0.993095</td>\n",
       "      <td>0.006174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>exponential</td>\n",
       "      <td>100</td>\n",
       "      <td>0.992828</td>\n",
       "      <td>0.006021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>exponential</td>\n",
       "      <td>80</td>\n",
       "      <td>0.992765</td>\n",
       "      <td>0.006340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>deviance</td>\n",
       "      <td>120</td>\n",
       "      <td>0.992556</td>\n",
       "      <td>0.006791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_max_depth   param_loss param_n_estimators  mean_test_score  \\\n",
       "0               2  exponential                140         0.993164   \n",
       "1               2  exponential                120         0.993095   \n",
       "2               2  exponential                100         0.992828   \n",
       "3               2  exponential                 80         0.992765   \n",
       "4               2     deviance                120         0.992556   \n",
       "\n",
       "   std_test_score  \n",
       "0        0.006315  \n",
       "1        0.006174  \n",
       "2        0.006021  \n",
       "3        0.006340  \n",
       "4        0.006791  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[[\n",
    "    'param_max_depth', 'param_loss', 'param_n_estimators',\n",
    "    'mean_test_score', 'std_test_score',\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b364e9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data score : 1.0\n",
      "Test data score : 0.9976484420928865\n"
     ]
    }
   ],
   "source": [
    "# get the predictions\n",
    "\n",
    "preds_train = search.predict_proba(X_train)[:,1]\n",
    "preds_test = search.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train data score : {}'.format(roc_auc_score(y_train, preds_train)))\n",
    "print('Test data score : {}'.format(roc_auc_score(y_test, preds_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493a8781",
   "metadata": {},
   "source": [
    "- It is still overfitting, we can reduce the no of estimators or play with other hyper params to get this fixed\n",
    "- As we can see in the above table, n_estimators = 140 and 120 doesnt have much difference on the performance but the no of tress are more, so we can reduce it to 120 instead of 140, maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5922d170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(loss='exponential', max_depth=2, n_estimators=120,\n",
       "                           random_state=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = GradientBoostingClassifier(n_estimators=120, max_depth=2, loss='exponential', random_state=0)\n",
    "\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b46d1752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data score : 0.9999999999999999\n",
      "Test data score : 0.9973544973544973\n"
     ]
    }
   ],
   "source": [
    "# get the predictions\n",
    "\n",
    "preds_train = gbm.predict_proba(X_train)[:,1]\n",
    "preds_test = gbm.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train data score : {}'.format(roc_auc_score(y_train, preds_train)))\n",
    "print('Test data score : {}'.format(roc_auc_score(y_test, preds_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66e6e58",
   "metadata": {},
   "source": [
    "- This still looks better than the earlier one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f16ea63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
